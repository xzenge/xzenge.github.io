{"pages":[{"title":"about","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"CSAPP Docker实验环境搭建","text":"CSAPP 的Docker实验环境在windows下的安装过程，MacOS下一致。 搜索ubuntu镜像1docker search ubuntu 拉取最新镜像1docker pull ubuntu:latest 配置并启动ubuntu容器 -it 中断交互式 -v 共享目录最好指定自己的的实验目录 (D:\\work\\workspace_c\\CSAPP_LAB:csapplab) -name 容器名称 /bin/bash 容器启动后运行bash1docker run -it -v D:\\work\\workspace_c\\CSAPP_LAB:/csapplab --name=csapp_env ubuntu:latest /bin/bash 配置ubuntu实验环境 更新apt软件源 1apt-get update 安装sudo 1apt-get instull sudo 安装vim 1apt-get instull vim 安装c/c++编译环境 12sudo apt-get install build-essentialsudo apt-get install gcc-multilib 退出容器1exit 停止容器1docker stop csapp_env 启动&amp;进入容器12docker start csapp_envdocker exec -it csapp_env /bin/bash","link":"/2020/10/11/CSAPP-Docker%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"title":"Harmonica","text":"开个坑，时不时分享下自己和口琴，权当记录自己和音乐那仅有的缘分了。 音乐白痴想要学乐器，网上随便一搜，大多数人都会推荐吉他，其次可能是电子琴。美其名曰吉他上手快，而且可以伴奏。那我这种五音不全加木耳肯定第一个就淘汰了,正巧这个时候在网上看到了一段视屏 龙登杰演奏的Flower Dance。 Flower Dance已经被各种乐器大神演绎过了，但龙登杰的半音阶真的是让我浑身鸡皮疙瘩。口琴虽然没有钢琴版优美的音色，也没有吉他版的自然，但是现场的感染力真的是无人能比。打个比方，钢琴适合为他人演奏，但口琴更像是给自己的音乐。最重要的是，对我们这种五音不全的意味着根本不用考虑唱歌这件事了。 口琴本身也分很多种：半音阶、复音、布鲁斯等。作为初学者的话个人认为布鲁斯会是比较好的选择。虽然不像半音阶能吹出全音符，也不像复音音阶比较多（其实我们小时候接触的大不符口琴都是复音口琴）。但布鲁斯本身小巧，在不掌握复杂技巧的前提下就能吹奏大量的乐曲。唯一值得注意的是，布鲁斯就如其名，过去是黑人乐手大量吹奏布鲁斯音乐时使用的。所以它的音色交半音阶个人觉得稍显浑厚。不过我觉得这也是布鲁斯口琴最大的特色。吹对的歌，或者说掌控了音色，那时候就是布鲁斯最强的时候。同时最为即兴，布鲁斯也是最为适合的，当然那都是大神们的领域就是了。 我的第一把布鲁斯口琴： Hohner(赫莱)在口琴界是几大品牌之一，最为德国的品牌其质量一直是广大琴友口口相传的。但这吧SilverStar就另当别论了，要比喻的话就类似德国宝马和国产宝马的区别。 首先做工就不经如人意，运气不好的话，有些音口可能会有气密性的问题。直接导致了有些音可能很难吹。 其次簧片反馈很诡异，这也是我个人的感觉。有些音很容易就吹出来了，但越是低音或者高音，吹奏难度就越高。口琴新手最大的一个坎就是压音，如果不巧需要压音的那几个音很难吹，那对新手来说可能是毁灭性的打击。。。记得最早练习压音的时候，这把SilverStar死活都没法成功，只要换了把更好的后才渐渐找到压音的感觉。日后回到这把SilverStar上居然神奇的也找到了压音的感觉，说来也是奇妙啊。 第二把口琴： 我的第二把口琴还是Hohner，但这把是真真切切的原厂口琴。小300的价格也算布鲁斯里的劳力士了。 这把口琴的造型就非常有特色，梳子型设计非常别致。和其他高端口琴一样，琴尺采用了全包围的设计。与日厂铃木的口轻相比，铃木给人的感觉更加圆润，而这把在圆润的前提下又不失豪放的设计。纯银色的琴身和红色的琴尺相得益彰。 和之前一把口琴吹起来，上嘴的那一刹那仿佛拿到了一个新乐器。绝对是要适应下才能正常演奏的，不过一旦习惯后，不论音色还是反馈都远远强于之前的那把贴牌货。更重要的是，我也是在这把口琴上学会的如何压音。如果可以，以后再买一把收藏了。","link":"/2020/06/13/Harmonica/"},{"title":"JVM 整理","text":"JVM 相关知识整理 内存分配 垃圾回收器的参数配置 类的加载 加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化-&gt;使用-&gt;卸载 加载流程 加载 代码中使用到这个类的时候，.class字节码文件就会加载这个类到JVM内存中。 链接 验证 根据JVM规范，校验.class文件。 准备 给加载的类分配内存空间，同时给类的static变量分配内存空间，并设置默认值0。clint() 解析 把符号引用替换为直接引用。 初始化 为类变量赋值：静态方法，静态变量，静态块。初始化一个类的时候，如果发现有父类还没初始化，会先初始化他的父类。 类加载器 加载器 BootStrap ClassLoader 加载lib目录下的类库 Extension ClassLoader 加载lib\\ext目录下的类库 Application ClassLoader 加载ClassPath下的类 自定义加载器 双亲委派机制 先找父亲加载，加载不了再找儿子加载 内存结构方法区、元空间、永久代存放类的定义，常量池等。matespace满后会触发Full GC。方法区垃圾回收：1.该类的所有实例已经被回收2.加载该类的ClassLoader已经被回收3.该类的Class对象没有被任何引用 程序技术器记录当前执行的字节码指令的位置。线程私有。 Java虚拟机栈保存方法信息。线程私有。 栈帧 局部变量表 操作数栈 动态链接 方法返回地址 其他 Java堆内存存放类的实例对象。 分代 年轻代 新生代进入老年代：默认15次 Eden区 默认新生代80%空间。新建对象产生在Eden区。Eden区满后会发生Minor GC。 Survivor0,1区 默认年轻代20%。Survivor 0:10% Survivor 1:10%。默认对象幸存15次后，会进入老年区。 动态年龄判断 当一批对象的大小大于Survivor区大小的50%，这批对象将不询问年龄，直接进入老年代。 老年代 进入老年代的规则 年龄超过MaxTenuring 动态年龄判断 超过PretenureSize的大对象 Eden区幸存对象超过Survivor区大小 JVM参数 -Xms Java堆内存的大小 -Xmx Java堆内存的最大大小 -Xmn Java对内存中的新生代大小。老年代=总大小-新生代 -XX:PermSize 永久代大小 -XX:MaxPermSize 永久代最大大小 -XX:MetaspaceSize 元空间大小 -XX:MaxMetaspaceSize 元空间最大大小 -Xss Java栈内存大小 -XX:MaxTenuringThreshold 对象在年轻代中幸存的最大轮数。默认15，且不能超过15. -XX:PretenureSizeThreshold 当对象大小超过该值时，对象直接进入老年代，不会进过年轻代。避免大对象在Survivor中多次复制，减少无谓的操作。 -XX:-HandlePromotionFailure 判断老年代内存大小是否大于之前每一次Minor GC后进入老年代的对象的平均大小。判断失败进行Full GC，再执行Minor GC。 -XX:SurvivorRatio 调整Eden区和Survivor区内存比率 XX:SurvivorRatio=8 ： Eden 80% -XX:+PrintGCDetils 打印详细的GC日志。 -XX:+PrintGCTimeStamps 打印GC发生的时间。 -Xloggc:gc.log 将CG日志输入到文件。 -XX:TraceClassLoading 追踪加载的类 -XX:TraceClassUnloading 追踪卸载的类 -XX:+HeapDumpOnOutOfMemoryError OOM时自动dump快照 -XX:HeapDumpPath=/usr/local/app/oom 将快照存放至指定目录 CMS -XX:CMSInitiatingOccupancyFaction 设置老年代占用多少比例时触发CMS -XX:+UseCMSCompactAtFullCollection Full GC后STW，整理内存碎片。 -XX:CMSFullGCsBeforeCompaction 默认0，设置多少次Full GC后进行内存碎片整理。 -XX:+CMSParallelInitialMarkEnabled 初始标记阶段开启并发执行 G1 -XX:+UseG1GC 指定G1垃圾回收器。 -XX:G1HeapRegionSize 手动指定G1的Region的大小。 -XX:G1NewSizePercent 调整新生代在堆中的占比。默认5%。 -XX:G1MaxNewSizePercent 新生代占比堆空间的最大大小。 -XX:MaxGCPauseMills 默认200ms。设置G1垃圾回收器GC时的最大停顿时间。 -XX:InitiatingHeapOccupancyPercent 默认45%。老年代占据的堆内存超多该值，将会进行新老生代的混合回收。 -XX:G1MixedGCCountTarget 一次G1混合回收过程中，最后阶段混合回收阶段分几次完成。默认8。 -XX:G1HeapWastePercent 默认值5%。混合回收阶段中，空间Region占比堆空间超多该值，会停止混合回收。 -XX:G1MixedGCLiveThresholdPercent 默认值85%。一个Region中的存活对象低于该值时才会被回收。 -XX:+CMSScavengeBeforeRemark 重新标记前，尽量执行一次Young GC。提前回收年轻代没有引用的对象，减少重新标记扫描的对象数，提高效率。 垃圾回收 可达性分析 对一个对象层层向上分析，判断是否有一个GC Root。 GC Root 本地变量表中的局部变量 方法区内的静态变量 java 引用类型 强引用 GC不会回收强引用 软引用 内存空间足够时，GC不会回收软引用 弱引用 GC时必定回收弱引用 虚引用 继承Object的finalize()方法，在该对象被回收的时候通知自己。 垃圾回收算法 年轻代 复制 在新生代幸存者0,1区使用。将标记为可用的内存复制到另外一片连续的内存区域中，并删除当前内存区域中的全部数据。 优点 不会产生内存碎片 缺点 增加内存的消耗 老年代 标记整理 标记存活对象，删除死亡对象，整理内存碎片。 优点 不会产生内存碎片。内存利用率高。 缺点 比起标记清楚，执行效率慢。 JVM垃圾回收器 年轻代 ParNew 多线程，复制算法。开启：-XX:+UseParNewGC调整回收线程数：-XX:ParallelGCThreads 老年代 CMS 标记清理算法 回收过程 初始标记 STW。标记所有GC Roots直接引用的对象，被直接引用的对象所引用的对象不会被标记。 并发标记 寻找被GC Roots间接引用的对象。 重新标记 STW。重新标记并发标记时产生的新对象。 并发清除 清理标记的对象。 缺点 默认启动垃圾回收线程：（CPU核数 +3）/4。本身会消耗CPU资源。针对浮动垃圾，初始标记后产生的垃圾没法回收。CMS回收期间，新生代进入老年代对象大于可用空间时，会发生Concurrent Mode Failure ，并自动使用Serial Old回收器替代CMS工作。 G1 基于复制算法。把Java堆内存划分为多个大小相等的Region。可以设置STW的时间，追踪每个Region里可回收对象的预估时间。G1中的分代是逻辑上的分代，同一个Region会随着分配的内存对象不同，而属于不同分代。每个Region的大小：堆大小/2048。新生代的Region同时分Eden和Survivor，可通过-XX:SurvivorRatio调整占比。适合大内存的机器，G1可以设置停顿时间，来确保对服务不会有较大的影响。 大对象 超多Region大小50%即为大对象。大对象可能横跨多个Region。空的Region都可以存放大对象。新老生代GC时都会回收大对象。 回收过程 初始标记 STW。标记所有GC Roots直接引用的对象，被直接引用的对象所引用的对象不会被标记。 并发标记 进行GC Roots的追踪，追踪所有存活对象。同时JVM会记录该阶段中新建或失去引用的对象。 最终标记 STW。通过多并发标记中JVM堆新增或失去引用的对象，进行重新标记。 混合回收 分析Region大小，执行效率。STW。在指定时间内进行回收。 问题 回收中发现Region空间不够时，将会SWT，并单线程进行标记、清除、整理，效率很低。 CG触发时间 Minor GC Eden区满时采用复制算法。 Old GC 1.老年代连续可用空间 &lt; 新生代历次GC后升入老年代对象内存和的平均大小。2.老年代不够存放，Minor GC后升入老年代的对象时。3.老年代内存使用率超过92%时（可设置）。 永久代GC 永久代不够使产生Full GC。 本地方法栈存放native方法。 堆外内存空间通过调用操作系统接口，直接分配对外内存空间。NIO-&gt;allocateDirect(DirectByteBuffer) 工具jstat通过jps查找java进程，再用jstat -gc PID查看GC状况。 指标 S0C From Survivor区大小 S1C To Survivor区大小 S0U From Survivor区当前使用大小 S1U To Survivor区当前使用大小 EC Eden区大小 EU Eden区当前使用的大小 OC 老年代的大小 OU 老年代当前使用的大小 MC 方法区（永久代、元空间）的大小 MU 方法区（永久代、元空间）当前使用的大小 YGC 系统迄今为止Young GC的次数 YGCT Young GC耗时 FGC 系统迄今为止Full GC的次数 FGCT Full GC的耗时 GCT 所有GC的总耗时 命令 jstat -gc PID 查看GC状况 jstat -gccapacity PID 堆内存分析 jstat -gcnew PID 新生代分析 jstat -gcnewcapacity PID 年轻代内存分析 jstat -gcold PID 老年代GC分析 jstat -gcoldcapacity PID 老年代内存分析 jstat -gcmetacapacity PID 元数据内存分析 jmap了解运行时的内存区域 命令 jmap -heap PID 打印堆内存相关参数设置。当前堆内各个区的基本情况。 jmap -histo PID 按照对象在内存中占用大小排序，降序。可以了解哪个对象在堆中占用了大量的空间。 jmap -dump:live,format=b,file=dump.hprof PID 生成内存快照并输出到文件。 jhat分析堆内存快照，可以使用工具内置的浏览器查看。 命令 jhat dump.hprof -port 7000 分析快照文件dump.hprof ，访问端口7000。 MAT内存分析工具 JVM优化总结调整新生代的大小尽量让每次Young GC后的存活对象⼩于Survivor区域的50%，都留存在年轻代⾥。尽量别让对象进 ⼊⽼年代。尽量减少Full GC的频率，避免频繁Full GC对JVM性能的影响 调整老年代碎片回收的频率CMS一次Full GC会产生内存随便，调整碎片整理的触发轮数，可以有效的降低Full GC产生的碎片从而降低Full GC的频次。 JVM参数模板-Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+UseParNewGC - XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection - XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSParallelInitialMarkEnabled -XX:+CMSScavengeBeforeRemark - XX:+DisableExplicitGC -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError - XX:HeapDumpPath=/usr/local/app/oom -XX:SoftRefLRUPolicyMSPerMB在有大量反射的情况下建议增大该值，保证软引用不会被马上回收 -XX:+DisableExplicitGC禁止显示执行GC性质System.gc() 使用缓存淘汰机制避免本地缓存无限增大，使得老年代常驻对象无法回收，从而导致的内存溢出和频繁的Full GC。 频繁Full GC的可能原因1.系统压力大，频繁Young GC后存活对象大于Survivor区，导致直接进入老年代。2.频繁产生大对象。3.对象始终不释放，导致内存泄漏。4.方法区频繁有类反射加载。5.错误使用System.gc()。 XMind: ZEN - Trial Version","link":"/2020/02/22/JVM-%E6%95%B4%E7%90%86/"},{"title":"NIO","text":"Buffer负责数据的存取。缓冲区及时数组。用于存储不同数据类型的数据。（boolean除外）通过allocate()获取缓冲区put()，get()缓冲区中的核心属性capacity:容量，表示缓冲区中最大存储数据的容量。一旦申明不能改变。limit:界限，表示缓冲区中可以操作数据的大小。limit后端的数据不能进行读写。position:位置，表示缓冲区中正在操作的位置。0&lt;=mark&lt;=posiotion&lt;=limit&lt;=capacityflip() 切换读取数据模式rewind() 可重复读clear()清空缓冲区，数据并没有被清空mark:标记，表示记录当前position的位置。可以通过reset()恢复到mark的位置。hasRemaining()：缓冲区中是否还有剩余的数据 实现类 ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 直接缓冲区&amp;非直接缓冲区可以通过isDirect()判断是否为直接缓冲区&amp;非直接缓冲区 直接缓冲区(物理内存映射文件) 通过allocateDirec()方法分配直接缓冲区，将缓冲区建立在物理内存中。可以提高执行效率。 物理磁盘-内核地址空间-物理内存映射文件-用户地址空间-应用程序 非直接缓冲区 通过allocatie()方法分配缓冲区，将缓冲区建立在JVM的内存中。 磁盘-内核地址空间-用户地址空间-应用程序 Channel负责缓冲区中的数据传输。Channel本身不存储数据，因此需要配合缓冲区进行传输。针对支持通道的泪提供了getChannel()方法：本地IO：FileInputStream/FileOutputStreamRandomAccessFile网路IO：SocketSeverSocketDatagramSocket 在JDK1.7中的NIO.2针对各个通道提供了静态方法open()咋JDK1.7中的NIO.2的Files工具类的newByteChannel() 实现类 FileChannel SocketChannel ServerSocketChannel DatagramChannel 通道之间的数据传输 transferFrom() transferTo() 分散与聚集 分散(Scatter) 分散读取(Scattering Reads)：将通道中的数据分散到多个缓冲区中 聚集(Gather) 聚集写入(Gathering Writes)：将多个缓冲区中的数据聚集到通道中 字符集(Charest) 编码 字符串 -&gt; 字节数组 解码 字节数组 -&gt; 字符串 Selector","link":"/2020/01/29/NIO/"},{"title":"Spring Boot","text":"容器IOC spring-context @Configuration 告诉Spring这是一个配置类 @Bean 给容器中注册一个Bean，类型为返回值的类型，id默认是用方法默认都是单例 AnnotationConfigApplicationContext @ComponetScan、@ComponetScans value：扫描@Service @Controller @Repositroy @ComponetexcludeFlters：排除的规则includeFilters：只需要包含的规则 FilterType.ANNOTATION 按照注解 FilterType.ASSIGNABLE_TYPE 按照给定类型 FilterType.ASPECTJ 使用ASPECTJ表达式 FilterType.REGEX 使用正则指定 FilterType.CUSTOM 自定义规则，必须实现TypeFilter类 @Scope SCOPE_PROTOTPE 多实例IOC容器启动不回去调用方法床架你对象，获取的时候创建对象 SCOPE_SINGLETON 单实例（默认值）IOC容器启动会调用方法创建对象放到IOC容器中 SCOPE_REQUEST 同一次请求创建一个实例 SCOPE_SESSION 同一个Session创建一个实例 @Lazy 懒加载：容器启动不创建对象。第一次使用（获取）Bean对象时调用创建对象放入容器 @Conditional 按照一定的条件进行判断，满足条件给容器中注册Bean需要实现Condition 接口：ConditionContext 判断条件能使用的上下文；AnnotatedTypeMetadate 注释信息 @Import 导入组件，id默认是组件的全类名（com.xxx.xxx.xx） ImportSelector 自定义逻辑返回需要导入的组件。返回值就是导入到容器中的组件全类名，方法不要返回null。AnnotationMetadata 当前标注@Import注解的类的所有注释信息。 ImportBeanDefinitionRegistrar BeanDefinitionRegistry：BeanDefinition注册类。调用registerBeanDefinition手工注册Bean FactoryBean 实现FactoryBean接口1.工厂Bean获取的是调用getObject创建的对象2.要获取工程Bean本身，需要给id前面加一个&amp; bean的生命周期 初始化 @Bean(initMethod) InitializingBean 通过让Bean实现该接口，实现Bean初始化逻辑 @PostConstruct BeanPostProcessor Bean后置处理器，在Bean初始化前后进行一些处理工作 postProcessBeforeInitialization 在初始化之前 postProcessAfterInitialization 在初始化工作之后 ApplicationContextAwareProcessor 实现该接口，Spring容器可以将当前容器传给实现类 InitDestroyAnnotationBeanPostProcessor 处理@PostConstruct，@PreDestory注解 AutowiredAnnotationBeanPostProcessor 处理@Autowired注解 销毁 @Bean(destroyMethod) 多实例的bean，容器不会调用销毁方法 DisposableBean 通过实现该接口，实现销毁逻辑 @PreDestory 属性赋值 @Value 基本数值 SpEL #{} 配置文件 ${} @PropertySource 读取外部配置文件，保存至环境变量中 自动装配 @Autowired 1.默认按照类型在容器中找相应的组件2.如果找到多个相同类型的组件，再将属性的名称作为组件的id组容易中寻找3.使用@Qualifier指定需要装配的组件的id4.自动装配默认一定要指定存在的属性（如果不强制指定，使用require=false）5.@Primary,让Spring进行自动装配的时候，默认是用首选的bean 构造器 构造器用到的自定义类型的值从IOC容器中获取如果组建只有一个有参构造器，这个有参构造器的@Autowired可以省略，参数位置的组件还是可以从容器中获取 方法 标注在方法，Spring容器创建当前对象，就会调用方法完成赋值方法使用的参数，自定义类型的值从IOC容器中获取 属性 值从IOC容器中获取 @Resource 可以和@Autowired一样实现自动装配，默认按照属性名称进行装配没有支持@Primary功能，reqiured=false @Inject 需要依赖javax.inject包，和Autowired一样，没有reqiured=false 实现xxxAware接口 在创建对象的时候，会调用接口的回调方法把Spring底层的组件注册到自定义的Bean中xxxAware功能使用xxxProcessor处理的 ApplicationContextAware 获取ApplicationContext BeanNameAware EmbeddedValueResolverAware Profile 加了环境表示的bean，只有这个环境被激活的时候才能注册到容器中，默认是default环境 启动参数 -Dspring.profiles.active=xxx 代码 1.创建一个aplicationContext2.设置需要激活的环境.getEnvironment().setActiveProfiles()3.注册朱配置类 .register()4.启动刷新容器 .refresh() AOP在程序运行期间动态的将某段代码切入到指定方法指定位置进行运行的编程方式spring-aspects容器中保存了组建的代理对象(cglib增强后的对象),这个对象里面保存了详细信息(比如增强器，目标对象) @Before 在目标方法之前切入：切入点表达式（指定在那个方法切入） @After 在目标方法之后切入：切入点表达式 @PointCut 切入点表达式 @AfterReturning 再放标方法正常返回之后运行 @AfterThrowing 在目标方法出现异常之后运行 @Aspect 告诉Spring当前类是一个切面类 @EnableAspectJAutoProxy 开启基于注解的AOP1.给容器中导入AspectJAutoProxyRegistrar，给容器中注册一个AnnotationAwareAspectJAutoProxyCreator AnnotationAwareAspectJAutoProxyCreator AspectJAwareAdvisorAutoProxyCreator AbstractAdvisorAutoProxyCreator AbstractAutoProxyCreator SmartInstantiationAwareBeanPostProcessor BeanFactroyAware JoinPoint JoinPoint一定要出现在参数表的第一位 目标方法执行 1.CglibAopProxy.intercept()。拦截目标方法的执行。2.根据PoxyFactory对象获取将要执行的目标方法拦截器链 a)如果没有拦截器链，直接执行目标方法 b)如果有拦截器链，把需要执行的目标对象，目标方法，拦截器链等信息出入创建一个CglibMethodInvocation，并调用proceed()方法 c)拦截器链触发过程 1.如果没有拦截器执行目标方法，或者懒机器的索引和拦截器数组-1大小一样(指定到了最后一个拦截器)，执行目标方法。 声明式事务1.导入相关依赖spring-jdbc2.配置数据源 JdbcTmplate3.给方法标注@Transactional4.@EnableTransactionManagement 开启基于注解的事物5.配置事物管理器管理事物 @Transactional @EnableTransactionManagement TransactionManagementConfigurationSelection 给容器中导入组件 AutoProxyRegistrar 给容器中注册InfrastructureAdvisorAutoProxyCreator组件 InfrastructureAdvisorAutoProxyCreator 利用后置处理器机制在对象创建后，包装对象，返回一个代理对象（增强器），代理对象执行方法利用拦截器链执行方法 ProxyTransactionManagementConfiguration 1.给容器中注册事物增强器 事物增强器要用事物注解信息 事物拦截器，保存了事物的属性信息，事物管理器，是一个MethodInterceptor，在目标方法执行时执行拦截器链 扩展原理BeanFactoryPostProcessorBeanFactory后置处理器 在BeanFactory标准初始化之后调用，所有的bean定义以保存在遭到beanFactory，但是bean还未创建 BeanDefinitionRegistryPostProcessor 在所有bean定义信息将要被加载，bean实力还未被创建时执行 ApplicationListener监听容器中发布的事件 1.写一个监听器，ApplicationListener实现类，来监听某个事件ApplicationEvent机器子类 2.把监听器加入到容器 3.只要容器中有相关事件的腹部，我们就能监听到这个事件： ContextRefreshedEvent：容器舒心完成(所有bean都完全创建)会发布这个事件； ContextClosedEvent：关闭容器会发布这个事件 4.发布一个事件，applicationContext.publishEvent() 容器的创建1.Spring容器在启动的时候，先会保存所有注册进来的Bean的定义信息 xml 注解2.Spring容器会合适的时机创建这些Bean 用到这个bean的时候，利用getBean创建bean，创建好以后保存在容器中 统一创建剩下所有的bean的时候，finshBeanFactoryInitialization()3.后置处理器 每个bean创建完成，都会使用各种后置处理器，来增强bean的功能4.事件驱动模型 ApplicationListener，事件监听事件派发，ApplicationEvenMulticator refresh() prepareRefresh() 刷新预处理工作:清缓存置状态 initPropertySources() 初始化属性设置，子类自定义个性化的属性设置方法。 getEnvironment().validateRequiredProperties() 检验属性的合法 earlyApplicationEvents 保存容器中的一起早起事件 obtainFreshBeanFactory() 获取BeanFactory refreshBeanFactory() 刷新BeanFactory工厂，创建BeanFactory对象。 getBeanFactory()【DefaultListableBeanFactory】 获取之前创建好的BeanFactory prepareBeanFactory() BeanFactory的预准备工作（BeanFactory进行一些设置）1.设置BeanFactory的类加载器，支持表达式解析器。。。2.添加部分BeanPostProcessor【ApplicationContextAwareProcessor】3.设置忽略的自动装配的接口，EnvironmentAware、EmbeddedValueResolverAware。。。4.注册可以解析的自动装配，我们能直接在仍和组件中自动注入：BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext5.添加BeanPostProcessor【ApplicationListenerDetector】6.添加编译是的AspectJ支持7.给BeanFactory中注册一些能用的组件：environment【ConfigurableEnvironment】、systemProperties【Map】 postProcessBeanFactory() BeanFactory准备完成后的后置处理工作，子类用过重写这个发方法来在BeanFactory初始化完成后进行更进一步的工作 invokeBeanFactoryPostProcessors() 执行BeanFactoryPostProcessor：BeanFactory的后置处理器，在BeanFactory标准初始化之后执行 执行BeanFactoryPostProcessor的方法：1.先执行BeanDefinitonRegistryPostProcessor 获取所有的BeanDefinitonRegistryPostProcessor 先执行实现了PriorityOrdered接口的 再执行实现了Ordered接口的 最后执行剩下的 2.再执行BeanFactoryPostProcessor的方法 先执行实现了PriorityOrdered接口的 再执行实现了Ordered接口的 最后执行剩下的 registerBeanPostProcessors() 注册BeanPostProcessor，Bean的后置处理器。1.获取所有的BeanPostProcessor，不同接口类型的BeanPostProcessor，在Bean船舰前后的执行实际是不一样的。 BeanPostProcessor DestructionAwareBeanPostProcessor InstantiationAwareBeanPostProcessor SmartInstantiationAwareBeanPostProcessor MergedBeanDefinitionPostProcessor initMessageSource() 初始化MessageSource组件（做国际化功能，消息绑定、解析）1.获取BeanFactory2.看容器中是否有id为messageSource的组件 如果有赋值给messageSource，如果没有自己创建【DelegatingMessageSource】 3.把创建好的MessageSource注册在容器中 initApplicationEventMulticaster() 初始化事件派发器1.从BeanFactory中获取applicationEventMulticaster的ApplicationEventMulticaster2.如果没有配置，创建SimpleApplicationEventMulticaster3.注册到容器中 onRefresh() 留给子容器的（子类）1.子类重写这个方法，在容器刷新的时候可以自定义逻辑 registerLiseners() 给容器中将所有的项目的ApplicationListener注册进来。1.从容器中拿到所有ApplicationListener组件2.将每个监听器添加到事件派发器中3.派发之前步骤产生的事件 finishBeanFactoryInitialization() 初始化剩下的所有单实例bean beanFactory.preInstantiateSingletons() 初始化剩下的单实例bean1.获取容器中所有的Bean定义2.拿到Bean的定义信息3.Bean不是抽象的，是单实例的，不是懒加载的 1.判断是否是FactoryBean，是否是实现FactoryBean接口的Bean 2.不是FactoryBean，用getBean创建对象 3.doGetBean() 4.先获取缓存中保存的单实例Bean。如果获取到，说明这个Bean之前被创建国（所有创建国的单实例Bean都是会被缓存起来的） 5.换种种获取不到，开始Bean的创建对象流程 6.标记当前bean已经被创建 7.获取Bean的定义信息 8.获取当前Bean依赖的其他Bean，如果有就按照getBean()把以来的Bean先创建出来。 9.启动单实例Bean的创建流程 1.createBean() 2.resolveBeforeInstantiation()让BeanPostProcessor先拦截返回代理对象【InstantiationAwareBeanPostProcessors】提前执行 3.如果前面的InstantiationAwareBeanPostProcessors没有返回代理对象 4.doCreateBean()创建Bean 1.创建Bean实例，createBeanInstance()利用工厂方法或者对象的构造器创建出Bean实例 2.applyMergedBeanDefinitionPostProcessors()，调用【MergedBeanDefinitionPostProcessors】 3.populateBean() Bean属性赋值 finishRefresh() 完成BeanFactory的初始化创建工作，IOC容器就创建完成 initLifecycleProcessor() 初始化和生命周期有关的后置处理器：LifecycleProcessor。写一个LifecycleProcessor的实现类，可以在BeanFactory的onRefresh(),onClose()进行拦截 getLifecycleProcessor().onRefresh() 拿到前面定义的生命周期处理器，回调onRefresh() publishEvent() 发布容器完成事件","link":"/2020/01/29/Spring-Boot/"},{"title":"hexo搭建问题【 no layout: index.html】","text":"由于在公司都是用MAC写博客，回到家想用Windows搭一套环境。 但是启动的时候总是提示no layout: index.html 的错误。 找了半天原因原来是个很傻的问题，这里mark下以免下次再犯。 模板是空的！！！模板是空的！！！模板是空的！！！","link":"/2019/09/07/hexo%E6%90%AD%E5%BB%BA%E9%97%AE%E9%A2%98%E3%80%90-no-layout-index-html%E3%80%91/"},{"title":"linux提供加载、处理动态链接库的系统调用方法","text":"我们知道目前Java提供的工具如javac、jps、jstat、jmap等都是通过Java的自举实现的。然而启动JVM的命令的java却是由C语言开发的。至于原因通过翻阅OpenJdk源码我猜测：是为了不提供JNI接口的前提下，需要动态链接调用JVM库所导致的。 java.c中动态链接jvm库相关代码 代码清单：src/solaris/bin/java_md_solinux.c 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182jbooleanLoadJavaVM(const char *jvmpath, InvocationFunctions *ifn){ void *libjvm; JLI_TraceLauncher(&quot;JVM path is %s\\n&quot;, jvmpath); libjvm = dlopen(jvmpath, RTLD_NOW + RTLD_GLOBAL); if (libjvm == NULL) {#if defined(__solaris__) &amp;&amp; defined(__sparc) &amp;&amp; !defined(_LP64) /* i.e. 32-bit sparc */ FILE * fp; Elf32_Ehdr elf_head; int count; int location; fp = fopen(jvmpath, &quot;r&quot;); if (fp == NULL) { JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } /* read in elf header */ count = fread((void*)(&amp;elf_head), sizeof(Elf32_Ehdr), 1, fp); fclose(fp); if (count &lt; 1) { JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } /* * Check for running a server vm (compiled with -xarch=v8plus) * on a stock v8 processor. In this case, the machine type in * the elf header would not be included the architecture list * provided by the isalist command, which is turn is gotten from * sysinfo. This case cannot occur on 64-bit hardware and thus * does not have to be checked for in binaries with an LP64 data * model. */ if (elf_head.e_machine == EM_SPARC32PLUS) { char buf[257]; /* recommended buffer size from sysinfo man page */ long length; char* location; length = sysinfo(SI_ISALIST, buf, 257); if (length &gt; 0) { location = JLI_StrStr(buf, &quot;sparcv8plus &quot;); if (location == NULL) { JLI_ReportErrorMessage(JVM_ERROR3); return JNI_FALSE; } } }#endif JLI_ReportErrorMessage(DLL_ERROR1, __LINE__); JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } ifn-&gt;CreateJavaVM = (CreateJavaVM_t) dlsym(libjvm, &quot;JNI_CreateJavaVM&quot;); if (ifn-&gt;CreateJavaVM == NULL) { JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } ifn-&gt;GetDefaultJavaVMInitArgs = (GetDefaultJavaVMInitArgs_t) dlsym(libjvm, &quot;JNI_GetDefaultJavaVMInitArgs&quot;); if (ifn-&gt;GetDefaultJavaVMInitArgs == NULL) { JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } ifn-&gt;GetCreatedJavaVMs = (GetCreatedJavaVMs_t) dlsym(libjvm, &quot;JNI_GetCreatedJavaVMs&quot;); if (ifn-&gt;GetCreatedJavaVMs == NULL) { JLI_ReportErrorMessage(DLL_ERROR2, jvmpath, dlerror()); return JNI_FALSE; } return JNI_TRUE;} 总结下Linux下动态链接的使用 dlopen以指定模式打开指定的动态链接库文件，并返回一个句柄给调用进程 方法定义1void *dlopen(const char *filename, int flag); filename 文件路径 flag RTLD_LAZY 暂缓决定，等有需要是再解出符号 RTLD_NOW 立即决定，返回前解除所有未决定的符号 方法使用12void *handle;handle = dlopen(动态链接库路径, RTLD_LAZY); dlsym通过句柄和连接符名称获取函数名或者变量名 方法定义1void *dlsym(void *handle, const char *symbol); 方法使用12ifn-&gt;CreateJavaVM = (CreateJavaVM_t) dlsym(libjvm, &quot;JNI_CreateJavaVM&quot;); dlclose卸载打开的库 方法定义1int dlclose(void *handle); 方法使用1dlclose(handle);","link":"/2020/09/24/linux%E6%8F%90%E4%BE%9B%E5%8A%A0%E8%BD%BD%E3%80%81%E5%A4%84%E7%90%86%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%BA%93%E7%9A%84%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E6%96%B9%E6%B3%95/"},{"title":"多级缓存","text":"起因项目平稳的已经运行快一年了，某天早上监控突然告警大量核心服务不可能，虽然运维紧急处理并重启了服务。但这种非正常的服务宕机着实让人捏了把冷汗（还好创业公司还没有生产事故惩罚机制）。 随后我们Dump下了服务起的日志，发现事故期间JVM存在大量的Full GC，配合CAT的监控指标发现某几个接口的调用量剧增。。。。大概我们是被刷接口了。 查看具体接口，发现前端反复查询配置信息而且没有做缓存，大量的大对象堆积不频繁Full GC才怪。。。。知道问题那我们就开始优化吧 缓存Spring Cache 注解 功能 Cacheable CacheEvict CachePut Caching spring boot cache 流程 多级缓存流程 springboot 开启缓存很方便 依赖org.springframework.boot:spring-boot-starter-cache 在启动类增加注解@EnableCaching 在想要增加缓存的方法或者成员变量上增加以下注解 启用多级缓存 引入组件 开启缓存 无参缓存 带参缓存1 带参缓存2 组合参数缓存","link":"/2019/09/04/%E4%B8%80%E4%B8%AA%E4%BA%8B%E6%95%85%E5%BC%95%E8%B5%B7%E7%9A%84%E7%BC%93%E5%AD%98/"},{"title":"分布式一致性算法整理","text":"分布式算法相关知识总结（施工中）总结当前使用较多的一种分布式一致性算法的原理及其运用。 Raft 角色最多只有一个Leader，正常工作时期只有Leader和Follower 成员 Leader 接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower 接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate Leader选举过程中的临时角色。 角色变化 Leader Leader在当前任期term中失去服务链接，将会变为Candidate。 Follower 1.节点初始状态为Follower。2.Follower超时没有收到Leader的消息，会转变为Candidate，并开始选举。 Candidate 1.选举成功成为Leader。2.选举失败成为Follower。3.超时重新选举，还是Candidate。 Leader选举1.Follower超时没有收到Leader的心跳时会发起选举，选举时会将自己的term+1，并转化为Candidate且投票给自己，并向集群内发送RequestVote RPC。 赢得最多选票成为Leader 收到其他Leader信息，被抢先选举 没有服务获得最多选票，等待重新发起选举 日志同步1.Leader接受客户端信息。2.Leader向Follower发起日志复制，AppendEntries RPC。3.Follower未成功接受时，Leader会持续向Follower发起AppendEntries RPC。4.大部分Follower返回成功时，Leader向客户端返回成功结果，并允许改条日志commit。 日志 日志包含索引，当前term号，和状态机的执行命令。 同步 1.相同索引和term号的命令是相同的。2.相同索引和term号之前的日志都是相同的。 Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目 安全性1.拥有最新的已提交的log entry的Follower才有资格成为Leader。2.Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。 日志压缩Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃。每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。 Snapshot 1.日志元数据。最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。2.系统当前状态。 Leader会以Snapshot的形式发给日志落后太多或新上线的Follower，使用InstalledSnapshot RPC。 PaxosXMind: ZEN - Trial Version","link":"/2020/03/01/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E6%95%B4%E7%90%86/"},{"title":"分布式事务其实很简单","text":"什么是分布式事务？为什么我们要有分布式事务？先聊聊我们的项目开发工作中随着业务的逐渐扩展，我们的业务系统也会慢慢变得庞大。拿借贷系统来说，从金融借贷产品的上架，商户的申请、审核，贷款的进件、KYC、放贷，再到用户的还款甚至催收。而业务往往为了快速落地，我们会将所有业务融入到一个服务中，快速开发、快速上线。好处自然是公司业务蹭蹭往上走，业务提出的需求也能快速落地并投放至市场，但长此以往开发测试人员会变得疲惫不堪。这里我们就要聊到服务的拆分，由于这次主要讲的是分布式事务，我们下次有时间再来讨论讨论微服务的拆分和现在大热门的DDD领域模型。 服务拆分后。。。在互联网公司工作的话，大家应该都经历过一个大系统，经过不停的迭代，最后拆成数个微服务的过程。其中的好处自然不用说，系统解耦、业务解耦、快速发版、更少的维护等等等等。但是一旦拆出多个微服务，我们也会遇到一个棘手问题。 为什么我们要有分布式事务？这个问题凸显了出来假设我们有这样一个业务：客户申请了一个贷款，这个时候我们需要做的是 收集用户信息 审核用户信息 创建贷款订单及分期订单等 选取投资人 放款 其中收集用户信息和审核用户信息并不是一个实时操作，我们可能会交由消息去异步处理。但是第三、四、五步是审核通过后一一执行的，当然我们也可以交由消息异步处理，但是试想一个场景。用户再分期购买产品的时候虽然对用户只是一次交易操作，但是我们后台可能已经把这笔交易作为一笔分期借款进行了落款。但是客户不知道，不是说异步处理不好，但如果能实时的告诉用户支付结果，是不是能提高用户体验和转换率呢。回头看下我们的系统，已经被拆成订单服务、用户体系服务、放款服务了，随之带来的是每个微服务有自己对应的数据库，分别保存的是订单信息、投资人|借款人信息、放款信息。一不做二不休，我们把以前同一个服务内的方法调用改成不同服务之间的异步调用，但随之而来的是生产上不时会出现漏数据或订单无法正常完成的问题。聪明的小伙伴应该早就发现了，为了保证分布式服务间调用的事务性，分布式事务就孕育而生了。 两阶段提交/XA常见于单系统操作多数据源。由于依赖数据库的事务，导致效率低，不适合高并发场景。 事务管理器流程 第一阶段 发起事务 取消事务 第二阶段 通知执行每一个任务 TCC适合对分布式一致性要求要的系统，如支付、交易等 流程 Try 对各个服务的资源进行检查，业务校验等。 Confirm 进行实际的操作 Cancel 错误发生时，对之前的操作进行回滚 问题业务耦合比较大，需要大量的业务代码支持 本地消息表可以保证事务的最终一致性，但不适用于高并发场景 流程 A系统业务操作后落消息表并MQ通知B系统 B系统接收消息后执行业务操作，并更新A、B信息消息状态 B系统未成功时，A系统会一直重试到成功 可靠消息最终一致性依赖RMQ的消息事务，和高可用，保证消息一定通知到，并最终保证事务的一致性 流程 A系统发送prepare消息至MQ，并处理业务 A系统处理业务成功后发送Confirm消息至MQ B系统收到Confirm消息后执行业务 最大努力通知方案可以允许一定程度上的事务失败，一般用在对分布式事务不要个的系统，比如日志收集等 A系统发送消息至MQ最大努力系统接收MQ通知并调用B系统XMind: ZEN - Trial Version","link":"/2020/03/01/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%95%B4%E7%90%86/"},{"title":"分支预测 GCC __builtin_expect 有用吗？","text":"我们日常编写的代码中常见的分支语句，解释行语言能够根据代码运行期间收集分支的跳转的趋势动态优化分支跳转。而编译言语由于编译后直接生成可执行文件，因此很难在编译期推断出最好的优化条件。GCC为开发者提供了手动优化分支预测的方法__builtin_expect，通过显示编程向编译器提供优化建议从而优化分支的走向。 编译器是如何处理分支条件的？使用__builtin_expect的分支是如何得到优化的？使用GCC默认的优化级别会有什么不同？ 为了解开这些疑惑，我们直接上代码。 平台 Ubuntu 20.04.1 LTS 内核 Linux b13a1870ebc6 5.4.39-linuxkit #1 SMP Fri May 8 23:03:06 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux 编译工具 gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;//x很可能为true#define likely(x) __builtin_expect(!!(x), 1) //x很可能为false#define unlikely(x) __builtin_expect(!!(x), 0)void foo(){ printf(&quot;foo\\n&quot;);}void foo1(){ printf(&quot;foo1\\n&quot;);}void doLikely(int a){ if(likely(a)){ foo(); }else { foo1(); }}void doLikelyNocall(int a){ int x; if(likely(a)){ x = a*a; }else { x = a+a; }}void doUnlikely(int a){ if(unlikely(a)){ foo(); }else { foo1(); }}void doUnlikelyNocall(int a){ int x; if(unlikely(a)){ x = a*a; }else { x = a+a; }}void normal(int a){ if(a){ foo(); }else { foo1(); }}void normalNocall(int a){ int x; if(a){ x = a*a; }else { x = a+a; }}int main(int argc, char **argv){ //为了排除常量导致编译器的优化，这里使用不定参数作为入参，防止编译器优化相关代码 int a = atoi(argv[1]); doLikely(a); doUnlikely(a); normal(a); doLikelyNocall(a); doUnlikelyNocall(a); normalNocall(a); return 0;} 开始编辑，这里显示的指定-O0 -O1 -O2 -O3这四个优化等级。 1234root@b13a1870ebc6:/workspace_c/builtin_expect# gcc -O0 -o test_0 builtin_expect.croot@b13a1870ebc6:/workspace_c/builtin_expect# gcc -O1 -o test_1 builtin_expect.croot@b13a1870ebc6:/workspace_c/builtin_expect# gcc -O2 -o test_2 builtin_expect.croot@b13a1870ebc6:/workspace_c/builtin_expect# gcc -O3 -o test_3 builtin_expect.c 将编译后的目标文件反汇编 1234root@b13a1870ebc6:/workspace_c/builtin_expect# objdump -d test_0 &gt;test_0.aroot@b13a1870ebc6:/workspace_c/builtin_expect# objdump -d test_1 &gt;test_1.aroot@b13a1870ebc6:/workspace_c/builtin_expect# objdump -d test_2 &gt;test_2.aroot@b13a1870ebc6:/workspace_c/builtin_expect# objdump -d test_3 &gt;test_3.a 最终我们得到了4个优化等级不同的汇编代码，并依次对比相关逻辑。 1.-O0等级下，编译器默认不执行任何优化，我们对比原始分支代码和经过__builtin_expect优化后的代码在汇编码上有何区别。 123456789101112131415161718192021222324252627282930313233343536370000000000001197 &lt;doLikely&gt;: 1197: f3 0f 1e fa endbr64 119b: 55 push %rbp 119c: 48 89 e5 mov %rsp,%rbp 119f: 48 83 ec 10 sub $0x10,%rsp 11a3: 89 7d fc mov %edi,-0x4(%rbp) #参数a存放至-0x4(%rbp)处 11a6: 83 7d fc 00 cmpl $0x0,-0x4(%rbp) #参数a和0比较 11aa: 0f 95 c0 setne %al #条件设置，al中保存~ZF。if a = 1 then al = 1 ; if a = 0 then al = 0 11ad: 0f b6 c0 movzbl %al,%eax #eax = 0000000000000000 -&gt; 00000000000000000000000000000000 or 0000000000000001 -&gt; 00000000000000000000000000000001 11b0: 48 85 c0 test %rax,%rax #判断eax是否为0 11b3: 74 0c je 11c1 &lt;doLikely+0x2a&gt; #eax = 0(a = 0)时，跳转至11c1，call foo1 11b5: b8 00 00 00 00 mov $0x0,%eax 11ba: e8 aa ff ff ff callq 1169 &lt;foo&gt; #eax!=0(a = 0)时，call foo 11bf: eb 0a jmp 11cb &lt;doLikely+0x34&gt; #跳转至11cb，结束 11c1: b8 00 00 00 00 mov $0x0,%eax 11c6: e8 b5 ff ff ff callq 1180 &lt;foo1&gt; 11cb: 90 nop 11cc: c9 leaveq 11cd: c3 retq 0000000000001265 &lt;normal&gt;: 1265: f3 0f 1e fa endbr64 1269: 55 push %rbp 126a: 48 89 e5 mov %rsp,%rbp 126d: 48 83 ec 10 sub $0x10,%rsp 1271: 89 7d fc mov %edi,-0x4(%rbp) #参数a存放至-0x4(%rbp)处 1274: 83 7d fc 00 cmpl $0x0,-0x4(%rbp) #参数a和0比较 1278: 74 0c je 1286 &lt;normal+0x21&gt; #如果a=0，则跳转至1286，执行foo1 127a: b8 00 00 00 00 mov $0x0,%eax 127f: e8 e5 fe ff ff callq 1169 &lt;foo&gt; #如果a!=0,则执行foo 1284: eb 0a jmp 1290 &lt;normal+0x2b&gt; #跳转至1290，结束 1286: b8 00 00 00 00 mov $0x0,%eax 128b: e8 f0 fe ff ff callq 1180 &lt;foo1&gt; 1290: 90 nop 1291: c9 leaveq 1292: c3 retq 通过对比，结果令人惊讶。虽然执行结果一直，但是没有经过_builtin_expect优化的分支判断，反而比标识_builtin_expect的汇编代码更加简洁。 分析Unlikely的汇编代码，也存在同样的问题，编译器貌似会多此一举增加一步的判断 1234567891011121314151617181900000000000011fe &lt;doUnlikely&gt;: 11fe: f3 0f 1e fa endbr64 1202: 55 push %rbp 1203: 48 89 e5 mov %rsp,%rbp 1206: 48 83 ec 10 sub $0x10,%rsp 120a: 89 7d fc mov %edi,-0x4(%rbp) 120d: 83 7d fc 00 cmpl $0x0,-0x4(%rbp) 1211: 0f 95 c0 setne %al 1214: 0f b6 c0 movzbl %al,%eax 1217: 48 85 c0 test %rax,%rax 121a: 74 0c je 1228 &lt;doUnlikely+0x2a&gt; 121c: b8 00 00 00 00 mov $0x0,%eax 1221: e8 43 ff ff ff callq 1169 &lt;foo&gt; 1226: eb 0a jmp 1232 &lt;doUnlikely+0x34&gt; 1228: b8 00 00 00 00 mov $0x0,%eax 122d: e8 4e ff ff ff callq 1180 &lt;foo1&gt; 1232: 90 nop 1233: c9 leaveq 1234: c3 retq 此外，我们也写了个非内部调用的版本，结果也是同样。编译器没有对_builtin_expect做出不一样的优化。 123456789101112131415161718192000000000000011ce &lt;doLikelyNocall&gt;: 11ce: f3 0f 1e fa endbr64 11d2: 55 push %rbp 11d3: 48 89 e5 mov %rsp,%rbp 11d6: 89 7d ec mov %edi,-0x14(%rbp) 11d9: 83 7d ec 00 cmpl $0x0,-0x14(%rbp) 11dd: 0f 95 c0 setne %al 11e0: 0f b6 c0 movzbl %al,%eax 11e3: 48 85 c0 test %rax,%rax 11e6: 74 0b je 11f3 &lt;doLikelyNocall+0x25&gt; 11e8: 8b 45 ec mov -0x14(%rbp),%eax 11eb: 0f af c0 imul %eax,%eax 11ee: 89 45 fc mov %eax,-0x4(%rbp) 11f1: eb 08 jmp 11fb &lt;doLikelyNocall+0x2d&gt; 11f3: 8b 45 ec mov -0x14(%rbp),%eax 11f6: 01 c0 add %eax,%eax 11f8: 89 45 fc mov %eax,-0x4(%rbp) 11fb: 90 nop 11fc: 5d pop %rbp 11fd: c3 retq 2.为了了解_builtin_expect是否真的有用，我们再看看其他优化等级 -O1。 1234567891011121314151617181920212223242526272829000000000000119b &lt;doLikely&gt;: 119b: f3 0f 1e fa endbr64 119f: 48 83 ec 08 sub $0x8,%rsp 11a3: 85 ff test %edi,%edi 11a5: 74 0f je 11b6 &lt;doLikely+0x1b&gt; 11a7: b8 00 00 00 00 mov $0x0,%eax 11ac: e8 b8 ff ff ff callq 1169 &lt;foo&gt; 11b1: 48 83 c4 08 add $0x8,%rsp 11b5: c3 retq 11b6: b8 00 00 00 00 mov $0x0,%eax 11bb: e8 c2 ff ff ff callq 1182 &lt;foo1&gt; 11c0: eb ef jmp 11b1 &lt;doLikely+0x16&gt;00000000000011f3 &lt;normal&gt;: 11f3: f3 0f 1e fa endbr64 11f7: 48 83 ec 08 sub $0x8,%rsp 11fb: 85 ff test %edi,%edi 11fd: 74 0f je 120e &lt;normal+0x1b&gt; 11ff: b8 00 00 00 00 mov $0x0,%eax 1204: e8 60 ff ff ff callq 1169 &lt;foo&gt; 1209: 48 83 c4 08 add $0x8,%rsp 120d: c3 retq 120e: b8 00 00 00 00 mov $0x0,%eax 1213: e8 6a ff ff ff callq 1182 &lt;foo1&gt; 1218: eb ef jmp 1209 &lt;normal+0x16&gt;00000000000011ee &lt;doUnlikelyNocall&gt;: 11ee: f3 0f 1e fa endbr64 11f2: c3 retq 观察-O1优化后的汇编代码，代码风格有了质的飞越。去除了公式化的参数传递，费劲的值比较。但是依然没有体现出_builtin_expect有没有的区别。同样的，我们的非调用版本由于无返回值，已经被编译器完全优化掉了。 我们再看看-O2。 123456789101112131415161718192021222324250000000000001210 &lt;doLikely&gt;: 1210: f3 0f 1e fa endbr64 1214: 85 ff test %edi,%edi 1216: 74 10 je 1228 &lt;doLikely+0x18&gt; 1218: 48 8d 3d e5 0d 00 00 lea 0xde5(%rip),%rdi # 2004 &lt;_IO_stdin_used+0x4&gt; 121f: e9 3c fe ff ff jmpq 1060 &lt;puts@plt&gt; 1224: 0f 1f 40 00 nopl 0x0(%rax) 1228: 48 8d 3d d9 0d 00 00 lea 0xdd9(%rip),%rdi # 2008 &lt;_IO_stdin_used+0x8&gt; 122f: e9 2c fe ff ff jmpq 1060 &lt;puts@plt&gt; 1234: 66 66 2e 0f 1f 84 00 data16 nopw %cs:0x0(%rax,%rax,1) 123b: 00 00 00 00 123f: 90 nop0000000000001290 &lt;normal&gt;: 1290: f3 0f 1e fa endbr64 1294: 85 ff test %edi,%edi 1296: 74 10 je 12a8 &lt;normal+0x18&gt; 1298: 48 8d 3d 65 0d 00 00 lea 0xd65(%rip),%rdi # 2004 &lt;_IO_stdin_used+0x4&gt; 129f: e9 bc fd ff ff jmpq 1060 &lt;puts@plt&gt; 12a4: 0f 1f 40 00 nopl 0x0(%rax) 12a8: 48 8d 3d 59 0d 00 00 lea 0xd59(%rip),%rdi # 2008 &lt;_IO_stdin_used+0x8&gt; 12af: e9 ac fd ff ff jmpq 1060 &lt;puts@plt&gt; 12b4: 66 66 2e 0f 1f 84 00 data16 nopw %cs:0x0(%rax,%rax,1) 12bb: 00 00 00 00 12bf: 90 nop 代码进一步的被优化，从汇编代码中可以看出，方法调用完全优化掉了栈上调用。去除了栈上传递，将call指令变为了jmp指令，进一步减少了指令上的开销。但结果仍然没有改变，_builtin_expect依然没有发光发热。 最后我们只能把希望寄托于-O3上看看了。 123456789101112131415161718192021222324250000000000001210 &lt;doLikely&gt;: 1210: f3 0f 1e fa endbr64 1214: 85 ff test %edi,%edi 1216: 74 10 je 1228 &lt;doLikely+0x18&gt; 1218: 48 8d 3d e5 0d 00 00 lea 0xde5(%rip),%rdi # 2004 &lt;_IO_stdin_used+0x4&gt; 121f: e9 3c fe ff ff jmpq 1060 &lt;puts@plt&gt; 1224: 0f 1f 40 00 nopl 0x0(%rax) 1228: 48 8d 3d d9 0d 00 00 lea 0xdd9(%rip),%rdi # 2008 &lt;_IO_stdin_used+0x8&gt; 122f: e9 2c fe ff ff jmpq 1060 &lt;puts@plt&gt; 1234: 66 66 2e 0f 1f 84 00 data16 nopw %cs:0x0(%rax,%rax,1) 123b: 00 00 00 00 123f: 90 nop0000000000001290 &lt;normal&gt;: 1290: f3 0f 1e fa endbr64 1294: 85 ff test %edi,%edi 1296: 74 10 je 12a8 &lt;normal+0x18&gt; 1298: 48 8d 3d 65 0d 00 00 lea 0xd65(%rip),%rdi # 2004 &lt;_IO_stdin_used+0x4&gt; 129f: e9 bc fd ff ff jmpq 1060 &lt;puts@plt&gt; 12a4: 0f 1f 40 00 nopl 0x0(%rax) 12a8: 48 8d 3d 59 0d 00 00 lea 0xd59(%rip),%rdi # 2008 &lt;_IO_stdin_used+0x8&gt; 12af: e9 ac fd ff ff jmpq 1060 &lt;puts@plt&gt; 12b4: 66 66 2e 0f 1f 84 00 data16 nopw %cs:0x0(%rax,%rax,1) 12bb: 00 00 00 00 12bf: 90 nop 可见，O3已经没有任何优化空间了，_builtin_expect的存在感也已然是0。 这次的实验是否失败呢，结果上看起来的确如此。但是我们并没有尝试更多的平台，同时各个平台的版本或GCC的版本都可能对编译的结果造成不同的影响。_builtin_expect到底有没有用？我能确信的是，再更加激进的优化等级下，_builtin_expect的存在感必然是稀薄的。但是GCC在遇到_builtin_expect时具体做了些什么，希望某一天阅读完GCC相关的源码后找到一个满意的答案吧！~","link":"/2020/12/14/%E5%88%86%E6%94%AF%E9%A2%84%E6%B5%8B-GCC-builtin-expect/"},{"title":"基于Flink实现简单的日志异常推送","text":"监控系统业务系统经常会接入各种监控系统或APM系统，从而实现生产问题的快速报警和定位。比如CAT、PingPong、skywalking等，虽然实现原理和架构略有不同，但都为业务系统提供了调用链跟踪、异常日志、DB异常、连接超时、JVM信息等报警。甚至我们可以在监控平台上定制自己的报警规则，监控系统会根据规则向关系人提供报警信息。 以上都是基于监控系统提供的功能实现各个维度的报警。最近在捯饬Flink，所以想能否用Flink实现一个简单的日志异常报警。话不多说，开始撸代码。 引入日志服务依赖由于系统已经全面接入阿里云日志平台，并且阿里云也非常有好的为我们提供了Flink阿里云Source的实现，所以我们只要引入阿里云提供的jar包即可，省去了自己实现的功夫。 12345compile &quot;com.aliyun.openservices:flink-log-connector:0.1.3&quot;compile &quot;com.google.protobuf:protobuf-java:2.5.0&quot;compile &quot;com.aliyun.openservices:aliyun-log:0.6.10&quot;// 由于当前只是用Source，所以不引入Sink模块// compile &quot;com.aliyun.openservices:log-loghub-producer:0.1.8&quot; 可以看到，阿里云日志通过protobuf协议进行序列化传输。 日志分析启动类参考官网文档，我们配置了阿里云日志服务的链接属性，指定了日志文件。此外我们还定义了interval参数为日志间隔；threshold为错误数；nameserverAddress为将错误信息发送至RockerMQ地址。结合上一篇文件，异常推送任务会将错误信息通过wechat推送给干系人。 1234567891011121314151617181920212223242526ParameterTool parameterTool = ParameterTool.fromArgs(args); String interval = parameterTool.get(&quot;interval&quot;); String threshold = parameterTool.get(&quot;threshold&quot;); String nameserverAddress = parameterTool.get(&quot;nameserverAddress&quot;); Properties configProps = new Properties(); // 设置访问日志服务的域名 configProps.put(ConfigConstants.LOG_ENDPOINT, &quot;xxxxxxxxxxxx&quot;); // 设置访问ak configProps.put(ConfigConstants.LOG_ACCESSSKEYID, &quot;xxxxxxxx&quot;); configProps.put(ConfigConstants.LOG_ACCESSKEY, &quot;xxxxxx&quot;); // 设置日志服务的project configProps.put(ConfigConstants.LOG_PROJECT, &quot;xxxxxxx&quot;); // 设置日志服务的LogStore configProps.put(ConfigConstants.LOG_LOGSTORE, &quot;xxxxxxxx&quot;); // 设置消费日志服务起始位置 configProps.put(ConfigConstants.LOG_CONSUMER_BEGIN_POSITION, Consts.LOG_END_CURSOR); // 设置日志服务的消息反序列化方法 RawLogGroupListDeserializer deserializer = new RawLogGroupListDeserializer(); final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); Properties producerProps = new Properties(); producerProps.setProperty(RocketMQConfig.NAME_SERVER_ADDR, nameserverAddress); DataStream&lt;RawLogGroupList&gt; logTestStream = env.addSource( new FlinkLogConsumer&lt;RawLogGroupList&gt;(deserializer, configProps)); 解析阿里云日志并转换为日志流12345SingleOutputStreamOperator&lt;LogInfo&gt; process = logTestStream .flatMap(new TransLogInfo()) .keyBy(&quot;podName&quot;) .keyBy(&quot;level&quot;) .process(new SplitLeveProcess()); 我们首先实现了FlatMapFunction接口，为的是将阿里云的日志流结构解析成我们自己想要的日志结构1234567891011121314151617181920212223242526272829303132333435363738public class TransLogInfo implements FlatMapFunction&lt;RawLogGroupList, LogInfo&gt; { @Override public void flatMap(RawLogGroupList value, Collector&lt;LogInfo&gt; out) throws Exception { List&lt;RawLogGroup&gt; rawLogGroups = value.getRawLogGroups(); if(rawLogGroups != null){ for(RawLogGroup rawLogGroup : rawLogGroups){ String nodeIp = &quot;&quot;; Map&lt;String, String&gt; tags = rawLogGroup.getTags(); if(tags != null){ nodeIp = tags.get(&quot;_node_ip_&quot;); } if(rawLogGroup != null){ List&lt;RawLog&gt; logs = rawLogGroup.getLogs(); if(!CollectionUtils.isEmpty(logs)){ for(RawLog log : logs){ if(log != null){ LogInfo logInfo = new LogInfo(); Map&lt;String, String&gt; contents = log.getContents(); if(contents != null){ logInfo.setNodeIp(nodeIp); logInfo.setReceiveTime(contents.get(&quot;@timestamp&quot;)); logInfo.setLevel(contents.get(&quot;_level&quot;)); logInfo.setAccountId(contents.get(&quot;accountId&quot;)); logInfo.setPodName(contents.get(&quot;_pod_name_&quot;)); logInfo.setTraceId(contents.get(&quot;traceId&quot;)); logInfo.setMessage(contents.get(&quot;nte_message&quot;)); logInfo.setAppName(contents.get(&quot;appName&quot;)); } out.collect(logInfo); } } } } } } } 将解析后的日志流按照容器名和日志等级分组(如果只是想处理ERROR级别的错误，也可以用Filter对level进行过滤)我们实现了KeyedProcessFunction接口，将ERROR日志分流进行处理123456789101112131415public class SplitLeveProcess extends KeyedProcessFunction&lt;Tuple, LogInfo, LogInfo&gt; { private static final String LEVEL_INOF = &quot;INFO&quot;; private static final String LEVEL_ERROR = &quot;ERROR&quot;; final OutputTag&lt;LogInfo&gt; outputTag = new OutputTag&lt;LogInfo&gt;(&quot;error-log&quot;){}; @Override public void processElement(LogInfo value, Context ctx, Collector&lt;LogInfo&gt; out) throws Exception { if(LEVEL_INOF.equals(value.getLevel())){ out.collect(value); }else if(LEVEL_ERROR.equals(value.getLevel())){ ctx.output(outputTag,value); } }} 得到ERROR日志侧输出流，处理错误日志流123456 DataStream&lt;LogInfo&gt; errorStream = process.getSideOutput(new OutputTag&lt;LogInfo&gt;(&quot;error-log&quot;){}); errorStream.keyBy(&quot;podName&quot;).process(new ErrorProcess(Long.valueOf(interval) * 1000,Integer.valueOf(threshold)))// .setParallelism(4) .map(new ToMessage()) .addSink(new RocketMQSink(new SimpleKeyValueSerializationSchema(null, &quot;body&quot;), new DefaultTopicSelector(topic), producerProps).withBatchFlushOnCheckpoint(true)); 针对错误日志处理，同样实现了KeyedProcessFunction接口，通过注册定时器判断interval周期内，错误数量是否超过threshold。如果超过则输出错误信息流，交由后面的算子处理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class ErrorProcess extends KeyedProcessFunction&lt;Tuple, LogInfo, AlertInfo&gt; { private long interval; private int threshold;// private transient SendWechatService sendWechatService; ValueState&lt;Integer&gt; cnt ; ValueState&lt;Long&gt; timer ; ValueState&lt;String&gt; pod ; ValueState&lt;List&gt; errorMsg ; public ErrorProcess(long interval,int threshold){ this.interval = interval; this.threshold = threshold; } @Override public void open(Configuration parameters) throws Exception { super.open(parameters); cnt = getRuntimeContext().getState(new ValueStateDescriptor&lt;Integer&gt;(&quot;cnt&quot;,Integer.class,0)); timer = getRuntimeContext().getState(new ValueStateDescriptor&lt;Long&gt;(&quot;timer&quot;,Long.class)); pod = getRuntimeContext().getState(new ValueStateDescriptor&lt;String&gt;(&quot;pod&quot;,String.class)); errorMsg = getRuntimeContext().getState(new ValueStateDescriptor&lt;&gt;(&quot;errorMsg&quot;,List.class)); } @Override public void processElement(LogInfo value, Context ctx, Collector&lt;AlertInfo&gt; out) throws Exception { pod.update(value.getPodName()); if(&quot;ERROR&quot;.equals(value.getLevel())){ if(timer.value() == null){ ctx.timerService().registerProcessingTimeTimer(ctx.timerService().currentProcessingTime() + interval); } cnt.update(cnt.value() + 1); List em = errorMsg.value(); if(em == null){ em = new ArrayList(); } em.add(value.getMessage()); errorMsg.update(em); }else { if(timer.value() != null){ ctx.timerService().deleteEventTimeTimer(timer.value()); cnt.clear(); timer.clear(); } } } @Override public void onTimer(long timestamp, OnTimerContext ctx, Collector&lt;AlertInfo&gt; out) throws Exception { if(cnt.value() &gt;=threshold){ AlertInfo alertInfo = new AlertInfo(); alertInfo.setErrorCnt(cnt.value()); alertInfo.setLevel(&quot;ERROR&quot;); alertInfo.setPodName(pod.value()); alertInfo.setMg(errorMsg.value()); String content = &quot;In &quot; + interval/1000 + &quot; seconds, pod[&quot; + pod.value() + &quot;] over &quot; + threshold + &quot; error happened ,error count[&quot; + cnt.value() + &quot;] detail:&quot; + &quot;\\n&quot; + &quot;\\n&quot;; for(int i = 1 ;i&lt;=errorMsg.value().size();i++){ content = content + &quot;[&quot; + i + &quot;]&quot; + errorMsg.value().get(i-1) + &quot; &quot; + &quot;\\n&quot;; } alertInfo.setContent(content); out.collect(alertInfo); } cnt.clear(); timer.clear(); errorMsg.clear(); } 后续算子将错误日志流转换成指定结构，并发给RocketMQ的Sink，交由错误推送任务进行wechat推送。12345678910public static class ToMessage implements MapFunction&lt;AlertInfo, String&gt; { @Override public String map(AlertInfo value) throws Exception { JSONObject messageBody = new JSONObject(); messageBody.put(&quot;alertMsg&quot;,value.getContent()); messageBody.put(&quot;alertTo&quot;,&quot;xxxxx&quot;); messageBody.put(&quot;bizType&quot;,&quot;&quot;); return messageBody.toJSONString(); }} 总结以上就是一个简单的错误日志分析及报警的流程，下次我们针对这个流程再写一篇测试文。同时这个流程中，我们对错误日志流采用的是侧流输出。所以在我们的主流中，我们还有很多正常日志值得我们分析和挖掘，后面我们也会围绕这些日志来做些有意思的东西，那这一次我们就先到这了。","link":"/2020/05/30/%E5%9F%BA%E4%BA%8EFlink%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E6%97%A5%E5%BF%97%E5%BC%82%E5%B8%B8%E6%8E%A8%E9%80%81/"},{"title":"基于Flink推送报警信息-测试","text":"上次我们简单的实现了如何通过Flink实现一个简单的wechat推送功能，这次我们就实际的运行起来看看。以下操作都是基于windows环境，为避免环境的影响全部采用docker部署。 搭建本地RocketMQ环境 拉取namesrv 和broker 镜像 docker pull rocketmqinc/rocketmq:4.4.0 启动namesrv docker run -d -p 9876:9876 -v D:\\work\\rocketmq\\data\\namesrv\\logs:/root/logs -v D:\\work\\rocketmq\\data\\namesrv\\store:/root/store –name rmqnamesrv -e “MAX_POSSIBLE_HEAP=100000000” rocketmqinc/rocketmq:4.4.0 sh mqnamesrv 配置broker.config 12345678brokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHbrokerIP1 = 192.168.1.2 启动broker docker run -d -p 10911:10911 -p 10909:10909 -v D:\\work\\rocketmq\\data\\broker\\logs:/root/logs -v D:\\work\\rocketmq\\data\\broker\\store:/root/store -v D:\\work\\rocketmq\\conf\\broker.conf:/opt/rocketmq-4.4.0/conf/broker.conf –name rmqbroker –link rmqnamesrv:namesrv -e “NAMESRV_ADDR=namesrv:9876” -e “MAX_POSSIBLE_HEAP=200000000” rocketmqinc/rocketmq:4.4.0 sh mqbroker -c /opt/rocketmq-4.4.0/conf/broker.conf 拉取控制台镜像 docker pull pangliang/rocketmq-console-ng 启动控制台 docker run -e “JAVA_OPTS=-Drocketmq.namesrv.addr=192.168.1.2:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false” -p 8080:8080 -t pangliang/rocketmq-console-ng RocketMQ 设置以上，我们就在本地环境简单的部署好了rocketMQ的运行环境 我们配置下Topic 启动Flink本地运行时环境 配置启动参数 –nameserverAddress 127.0.0.1:9876 –consumerGroup flinkGroup –consumerTopic AlertWechatTopic 启动Flink本地运行时Job 模拟一条报警信息 查看报警信息 总结通过简单的操作，我们就可以定义一套统一的wechat告警信息发送机制。业务系统、告警系统、或是Flink其他的Job不需要关心告警推送的细节。只要向统一的Topic中推送告警信息，告警推送任务就是实时的把错误信息推送至wechat中。接下来，我们将围绕告警的核心功能：数据的采集、数据的分析。基于Flink来设计一个统一的报警平台。","link":"/2020/05/21/%E5%9F%BA%E4%BA%8EFlink%E6%8E%A8%E9%80%81%E6%8A%A5%E8%AD%A6%E4%BF%A1%E6%81%AF-%E6%B5%8B%E8%AF%95/"},{"title":"基于Flink设计统一报警平台","text":"最近在整理后端已有的错误报警，主要分两大类： 异常报警 基于监控系统。如CAT、pingpong、skywalking等APM系统的错误异常监控。开发人员针对异常类型，制定相应的阈值。对代码运行时异常、sql异常、网络异常等进行指标监控。当异常超过指定阈值时推送异常信息。我们的后端系统是基于CAT进行监控，监控的指标和配置都要人为进行配置，异常信息的推送需要开发并与CAT对接，同时微信推送这块异常信息有限，往往要通过邮件告警和登录CAT平台查看才能大概了解错误的类型。这点长期被开发人员诟病，虽然我们能够通过修改CAT的源码来改善上诉问题。但对于程序员来说，更加直观的堆错误信息进行处理是再好不过的事情。 基于系统指标。有别于服务异常，系统指标有更灵活的采集方式。我们采用了Spring Merics，基于Prometheus搭建了系统指标的监控体系，结合Grafana将近实时的系统指标展现至屏幕。同样遇到系统指标异常的时候，如Heap空间使用量异常，CPU飙高，内存告急等情况，我们通过Grafana的自定义告警将错误推送给相关开发。 业务告警 基于实时数据。通过对业务流程的埋点，将采集的实时数据进行计算比较。并将异常的业务数据进行推送告警。 基于离线数据。定时分析离线数据，推送异常业务数据告警。 以上大概介绍了监控的几个方向及其落地方式，通过分析我们可以将整个监控行为抽象成一个数据流：监控数据源–&gt; 监控数据清洗 –&gt; 监控数据计算 –&gt; 推送报警 基于这个结论，正式我们会开始研究并探索Flink的契机。面对目前后端形形色色的监控方式及处理流程，每一个部分都是割裂的，无法统一思想的。面对不同的监控场景时，我们要考虑不同接处理手段，这变相的增加了开发人员的人力资源。 为此我们考虑怎样可以最大限度的统一各个报警的流程，并提供一个统一的处理平台。这个时候Flink来到了我们面前。 Flink是什么相比不用介绍了，官网已经介绍的相当详细了：https://flink.apache.org/ 上面抽象的监控流程：监控数据源–&gt; 监控数据清洗 –&gt; 监控数据计算 –&gt; 推送报警 用Flink可以表示为：Source–&gt; ETL–&gt; Operator–&gt; Sink 结合上面的分析，我打算先从推送报警功能入手。利用Flink的流式处理能力，开发一个统一的报警出口任务。 数据源数据源我们打算采用RocketMQ。创建一个统一的报警推送Topic，定义统一的报警消息格式。 Topic AlertWechatTopic Body {“alertMsg”:””,“alertTo”:””,“bizType”:”” } 算子 应用RocketMQ-Extend提供的Flink支持，官方继承了RichParallelSourceFunction类。实现了注册Consumer，拉取Topic下的消息。 官方提供的序列化方法仅有针对key和value的String序列化SimpleKeyValueDeserializationSchema。在运用上是满足的，但是后期编程上可能自定义会更加方便。后期我们会考虑扩展序列化方式或是官方提供的拉取消息源码，做到更灵活的消息格式传输。 将从RocketMQ中拉取到的消息做Map，格式化成我们希望的结构。 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) { ParameterTool parameterTool = ParameterTool.fromArgs(args); String nameserverAddress = parameterTool.get(&quot;nameserverAddress&quot;); String consumerGroup = parameterTool.get(&quot;consumerGroup&quot;); String consumerTopic = parameterTool.get(&quot;consumerTopic&quot;); StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); SendWechatService sendWechatService = new SendWechatService(); // enable checkpoint env.enableCheckpointing(3000); Properties consumerProps = new Properties(); consumerProps.setProperty(RocketMQConfig.NAME_SERVER_ADDR, nameserverAddress); consumerProps.setProperty(RocketMQConfig.CONSUMER_GROUP, consumerGroup); consumerProps.setProperty(RocketMQConfig.CONSUMER_TOPIC, consumerTopic); env.addSource(new RocketMQSource&lt;Map&gt;(new SimpleKeyValueDeserializationSchema(null,&quot;body&quot;),consumerProps)) .name(&quot;rocketmq-source&quot;) .map(new MapFunction&lt;Map, WechatAlertInfo&gt;() { @Override public WechatAlertInfo map(Map value) throws Exception { String body = (String)value.get(&quot;body&quot;); WechatAlertInfo wechatAlertInfo = JSONObject.parseObject(body, WechatAlertInfo.class); return wechatAlertInfo; } }).addSink(new WechatSink()) .name(&quot;wechat sink&quot;); try { env.execute(&quot;send to wechat&quot;); } catch (Exception e) { e.printStackTrace(); } } 将格式化完成的数据源输出到我们自定义的Sink中，该sink的功能为发送wechat信息。 12345678910111213public class WechatSink extends RichSinkFunction&lt;WechatAlertInfo&gt; { private transient SendWechatService sendWechatService; @Override public void open(Configuration parameters) throws Exception { sendWechatService = new SendWechatService(); } @Override public void invoke(WechatAlertInfo value, Context context) throws Exception { sendWechatService.sendMessage(value.getAlertMsg(),value.getAlertTo()); }} 以上我们就简单的实现了将RocketMQ中的报警消息推送至wechat的功能，下次我们把代码跑起来看看。","link":"/2020/05/16/%E5%9F%BA%E4%BA%8EFlink%E8%AE%BE%E8%AE%A1%E7%BB%9F%E4%B8%80%E6%8A%A5%E8%AD%A6%E5%B9%B3%E5%8F%B0/"},{"title":"我为什么会手撸一个配置中心--介绍篇","text":"nadia-config是一款基于spring boot的配置中心，能够集中化管理不同环境、不同版本的集群配置，并提供配置的实时更新、回调、审批、权限管理等功能。 https://github.com/nadia-repository/nadia-config Nadia Config Center组件介绍 nadia-client nadia-server Release-Note v1.0 主要目标： 兼容springboot框架，业务系统无需代码变更 快速接入，jar包引用 配置动态更新，实时生效 支持集群分组，配置差异化 提供配置统一变更平台，支持平台用户的权限管理和配置变更的权限管理 部署图 项目构成 nadia-config 项目根目录 nadia-client 客户端 nadia-core 通用代码 nadia-server 服务端 nadia-web 前端页面 nadia-demo 客户端demo docs 文档 desgin 设计文档 sql 服务端脚本 DDL.sql 建表 DML.sql 初始数据 管理平台介绍1. 登录页面 2. 注册页面 3. 主界面根据登录用户的角色不同，菜单按钮会有相应变化 4. 配置管理–元数据管理元数据管理是所有配置的基础，客户端使用配置项时需要指定相关的元数据 名词解释 Application 系统名称，客户端可以指定使用任意一套系统下的配置。 Group 组名称，客户端指定系统后，仍需要指定使用系统下的某个组。若不强制指定，客户端启动后会默认使用Default组下的配置，后期可使用组切换功能切换至不同组。 功能说明 Add 新增Application，同时新增默认Group(Default)。 Delete 删除Application\\Group信息。当前Group如果正在被使用，或当前组为Default组且存在非Default组时，不能删除。Defualt组删除后将同时删除Application。 Compare 比较同一Application下不同Group的配置差异，可多选，但至少选两个组。 Edit 修改Application信息 Group 新增组。可选择从某个组复制所有已发布配置项，或生产新的空组。 Instances 可将某实例调整至另一组。 Inscance 查看弄实例当前的配置与服务端配置的差异。 5. 配置管理–配置项管理配置项管理提供具体配置的增删改查、发布等功能 名词解释 Key 配置项的key，与客户端中@Value({key})相对应 Value 值 Status new 新建配置 edited 配置已变更，带审批 approved 配置审批通过，可发布 published 配置已发布 removing 配置删除，待审批 deleted 配置已删除，不显示 invalid 配置无效，不显示 功能说明 Add 新增配置，可选择配置的可见权限。若不选择，则该配置为当前登录用户的角色可见。需要审批。 Delete 删除配置，需要审批。 Export 导出配置。 Import 导入配置，需要审批。 Edit 编辑配置，需要审批。 Instance 查看当前配置的使用情况。 History 配置修改历史 6. 配置管理–配置项分配配置项分配提供全局的角色配置可见权限设置。 功能说明 Allocate 分配角色可见配置 7. 消息中心–操作日志提供管理平台所有增删改的操作日志查询和回溯。 8. 消息中心–任务中心提供审批查看、审批操作(通过、拒绝)等功能。 Pending Task 待审批列表，提供审批通过、决绝，审配内容查看等功能。 Processing Task 审批进度列表，提供审批进度的查询。 Complete Task 完成任务列表，提供历史审批通过、拒绝的任务的查询。 9. 消息中心–操作日志提供客户端上报日志的查询。 10. 用户中心–角色管理提供角色的增删改查，角色的菜单权限、按钮权限的设置。 11. 用户中心–用户管理提供用户的增删改查，用户的角色分配设置。","link":"/2020/03/20/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E4%BB%8B%E7%BB%8D%E7%AF%87/"},{"title":"我为什么会手撸一个配置中心-设计篇（一）","text":"开篇从这篇开始，我们开始介绍整个配置中心的设计思想和架构的流程，主要会分为下面几个部分： 配置中心基础功能分析 配置中心技术选型 配置中心架构部署 基础功能分析–配置结构开始设计前我们先分析下一个配置中心到底需要哪些功能，同时工作中有哪些痛点是可以通过配置中心来解决的。 1.配置的管理原始的配置项管理大量采用了代码维护的方式，如spring的yml配置文件、代码中的@Value注解、各种中间件的配置文件等。不仅不利于配置的动态变更，更不利于统一管理配置信息，因此现有的配置中心解决方案会通常会将配置中心分为客户端和服务端。 客户端负责业务系统的配置收集与实时同步等。 服务端负责配置的统一管理和实时更新等。 结合上面的思路，我们在设计的初期也会将整个配置中心的技术架构分为客户端和服务端两部分。 回到配置管理的话题上，我们还需要考虑一个重要的功能点【如何管理配置】。这里的“管理”不单单只是将配置在某个页面上给用户展示而已，还要细化到： 配置如何划分范围？ 配置差异化如何处理？ 配置权限如何处理？ 配置如何划分范围？各个业务服务连接到配置中心后，他们都有怎么不同的配置，我们不能把他们的配置全部混为一谈。不同的服务的配置有自己的作用域，多个相同服务共享同一个作用域下的配置。 通过服务来划分配置范围是一个办法，我们在编写代码的时候其实也是这么处理的。但是仅仅如此是不够的。我们可以想象一个场景，业务场景上我们经常会遇到AB test，我们解决的办法常常是通过灰度发布或蓝绿发版。通过不同的规则将前端流量引向相同服务的不同版本从而实现生产上的差异化。 如果我们只是简单的通过服务来划分配置，但遇到上诉问题的时候往往痛疼不已。1.0 Ver需要看到A文案，1.1 Ver需要看到B文案。我们假象下，如果通过过去的配置文件方式，我们要怎么处理？首先要在代码里判断当前服务的版本，然后根据不同的版本读取不同的配置，最终达到不同版本不同展示效果的功能。 1234567891011121314@Vaule(&quot;{test.a}&quot;)private String testA;@Vaule(&quot;{test.b}&quot;)private String testB;public void getTest(String version) { if(&apos;1.0&apos;.equel(version)){ System.out.println(testA); }else if(&apos;1.1&apos;.equel(version)){ System.out.println(testB); }} 可能会有更好的处理方法，但大多数情况下我们会像上面写代码。长此以往可想而知，后面的同学不知道之前的逻辑就看不懂这段代码在写什么。而且每次有版本的变更，都需要硬编码。 那有没有更优雅的解决方案，既然我们都有配置中心了，同时我们的配置也都交由配置中心管理了，配置变更时我们也能实时的同步配置。那么我们能不能区分出相同服务的差异化配置呢？ 答案肯定是可以的。在已服务作为配置的作用域下，我们再定义一个组的概念： Application Group Service1 Default Service1 V1.0 Service1 V1.1 Service2 Default 同一个应用可以划分多个组，每个组中的配置存在差异化，相同配置的服务可以使用同一个组的配置。 以上就是我们划分配置范围的过程，既可以解决配置的差异化，也可以将各个服务的配置统一管理起来。当然这个配置的模型还需要不断的进化，比如：我们是否可以提炼出相同的配置，类似于jar在我们服务中相互引用的方式一样，在我们给个应用中共享。未来我们也会针对类似的需求不断的优化。","link":"/2020/03/24/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E8%AE%BE%E8%AE%A1%E7%AF%87/"},{"title":"我为什么会手撸一个配置中心-设计篇（二）","text":"基础功能分析–配置管理&amp;维护上文我们分析了配置域管理相关的功能，这次我们要分析下配置中心的核心功能：配置更新。我们将从几个角度分析配置更新功能： 客户端配置收集与本地维护 服务端配置管理 配置的热更新 客户端配置收集与本地维护首先我们来讨论下我们平时使用配置的场景，前面一篇我们提到过，通过spring的@Value我们可以本地的管理配置。除此以为我们也可以实现自身的配置管理机制，最常见的如数据库管理并加载、KV中间件存储并加载、本地文件存储并加载等。 考虑到项目本身希望更少的依赖第三方服务，同时能够实现配置的收集和管理，spring提供的@Valule不失为一个不错的选择。首先，spring容器会为我们自动收集并管理配置信息；其次，也提供了良好的环境配置隔离和本地配置维护。如果我们能够获取spring容器中维护的配置对象那不就能手工干预客户端配置的维护过程吗！ 服务端配置管理相比客户端配置的管理，服务端就容易很多。通过上篇的分析，我们完全能够构建出自己的配置项结构，并交由DB持久化从而达到服务端配置管理的功能。 配置的热更新有了之前的客户端配置的收集和服务端配置管理的分析，我们要实现一套配置的热更新的技术方向就非常明确了。 首先，客户端启动的时候，我们需要从远程服务端拉取到最新的配置，如果拉取不到则使用本地默认的。 其次，为了实现热更新。每当服务端对配置进行变更后，需要实时通知相应的客户端，并且客户端要同时更新最新的配置。 其他以上功能保证了我们的配置中心最基本的配置管理功能的整个生命周期。但围绕整个配置中心，还有许多其他功能需要分析，如配置的权限、用户的管理等。接下来的博客中，我们讲会讨论实现一个完整的配置中心，我们至少还需要哪些功能。最后围绕这些功能，我们会进入下一个重要篇章：选型篇。 先做一个预告，后面的更新我们会围绕以下几个功能去展开： 选型 功能实现与源码 与其他配置中心的比较 未来的优化与展望","link":"/2020/04/11/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E8%AE%BE%E8%AE%A1%E7%AF%872/"},{"title":"我为什么会手撸一个配置中心-设计篇（三）","text":"功能&amp;架构选型在做具体的架构选型前，先要明确两个问题：我们的技术栈是什么？我们是为怎样的技术团队提供服务的。 选型前的讨论当前公司后端团队大量的采用了JAVA的技术栈，随着公司的发展围绕着Spring Cloud全家桶，团队已经搭建了相当多的业务服务。可以说我们设计的配合中心服务在最大限度上会以JAVA为基础，围绕着Spring的生态圈进行设计并开发。 那么回到我们之前的架构选型话题，可以将问题改为：如何围绕Spring的生命周期，实现一套配置灵活、管理简洁、值热更新的系统。 确定我们必须结合Spring后，接下来需要明确的就是，如何实现配置的热更新。目前开源的配置中心有这么几种解决方案： 方式|中间件|优点|缺点|—|—|—|—||服务端调用客户端Api进行推送|无需|实现简单无需引入第三方中间件|依赖Http请求过于重自定义协议开发复杂需要自己保证请求的可靠性 ||客户端调用服务端Api进行拉取|无需|实现简单无需引入第三方中间件|依赖Http请求过于重自定义协议开发复杂需要自己保证请求的可靠性 ||依赖第三方中间件推送|Zookeeper、Redis、Nasco等|开发简单、不需要自己实现通讯可依赖中间件自身的HA做高可用|增加了项目的复杂度需要考虑中间件和当前项目的冲突问题| 对比了市场上的设计和我们的自身的人力成本，我们决定引入一款成熟中间件来解决大部分的通讯和配置发现问题。这个时候摆在我们面前的可选项其实还是很有限的，能胜任我们的需求的无非就是Zk、redis、MQ这几个。 这几个耳熟能详的中间件上来我们就放弃了zk，考虑主要有以下几点。 zk不适合做大量数据的存储，特别是配置这种结构化的数据。虽然zk的CP特性能为我们带来精准的配置推送特性，但是遇到大量的配置内容zk就显得力不从心。 zk的snapshot功能，一旦发现数据对其问题，需要停机人工处理。 近年来zk在服务注册发现上大展拳脚，但我始终认为zk在作为注册中心时会显得捉襟见肘，元数据管理才是它真正运用的领域。这一点正好契合我们的契机，不过不巧的是我们想要开发的并不是一个分布式的配置中心，或者说分布式并不是我们的中心。反而分布式的配置管理才是我们最好的选择。 剩下就是MQ和redis中做选择，他们两个就比较好抉择了。MQ和Redis都可以做到HA、变更的实时推送、但是MQ没法做到数据的管理。加上我们的系统里已近大量的使用到了redis，对redis的操作也比较熟悉。最终我们选择了redis作为中间件为我们的配置中心做配置的统一管理。","link":"/2020/04/12/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E8%AE%BE%E8%AE%A1%E7%AF%873/"},{"title":"我为什么会手撸一个配置中心--起源篇","text":"聊聊后端的工作作为一个后端狗最怕的有几件事： 需求做也做不完就罢辽，隔三差五的业务同学还会跑来说“大锅，昨天上架的产品麻烦调整下文案”。。。 好不容易做完了需求并且熬到了上线，第二天产品过来说“老弟，那个需求被监管部门勒令下架了，能把那个功能下了不”。。。 代码敲的开心的时候，隔壁老大跑过来说“兄弟，之前那个XX报表不错啊，也定时发我一份”。。。 上面的场景大家认识我的不要对号入座哈，作为个后端狗，最怕的就是重复劳动。 产品的文案、业务的开关、报表的收件人等等这些我们都可以叫做业务配置，一个合格的开发也能在需求设计阶段将这些配置从需求中提炼出来并进行配置化，方便日后的变更。那么，不是说配置能变更我们就没事了。 首先，如果基于spring开发的小伙伴肯定会想到spring自带的配置文件。通过配置文件的隔离，我们完全能够隔离出dev、staging、prod甚至更多环境的配置。每当配置有变更我们只需要修改相应环境的配置，并重新部署就OK了。 这样好吗？答案是没什么不好。但是优雅吗？那必须是挫的一塌糊涂。互联网的根基就是快速尝试、快速落地、反复尝试从而寻找到最优的解决方案。业务在不断的尝试过程中，或许会蹦出个大神拍着脑袋说“我觉得客户要的就是这个，这么那么做准没错”。但现实往往证明我们都是普通人，成为别人肚子里的蛔虫那是多么困难的一件事。所以需求的反反复复，代码的来来回回就是一个后端狗的日常。 配置中心的出现那在这种快速变化的场景下，我们作为开发能做些什么呢？答案其实很简答，古人都说了“大道化简”，那自然是有变化我们就拥抱变化。但一个聪明或者说懒惰的程序员在拥抱变化的同时最重要的工作就是寻找那个不变。代码的抽象、业务的抽象时我们日后服务搭建的根基。自然我们上面说道的配置当然也是。 聪明的程序员早就把这些繁杂的工作抽离了出来，配置中心而然而然的孕育出世。百度的Disconf、携程的Apollo、阿里的Nacos、Spring Cloud的Spring Cloud Config。后面我会专门聊聊这几个常见的配置中心的优劣。 我为什么手撸个配置中心那还要回到1年前，我们公司最为创业公司，业务刚刚起步。为了快速的业务落地，我们也是能来什么就来什么，时间长了我们发现了一个很重要的问题：发版成分太高。 相信每个做开发的小伙伴都有体会，晚上发版是一件多么让人惆怅的事情啊。。。但更让人惆怅的是，本来只是一个小小的配置变更，却还要等到晚上才能重新上线，着实让人受不了。从那个时候开始，我们就打算引入配置中心了。 首先调研配置中心的小伙伴经过几个现存开源系统的比较，最后选定了百度的Disconf。说上就上，Disconf就在我们的系统中愉快的奔跑起来了。 1年过去了，系统越来越复杂，业务越来越繁琐，当初那个人见人爱的Disconf不时的变成了我们午饭时诟病的谈资。当然并不是Disconf本身不好，不过失去维护的社区本身也是它问题的一环。但最重要的一点是，Disconf本身已经慢慢不适合我们的业务了。可能会有些小伙伴说，那就使用更强大的Apollo，或者Nacos。Apollo本身固然强大，但一个第三方系统始终无法契合我们现在的业务场景，Nacos也有同样的问题，才外由于我们使用的是Spring Cloud的全家桶，若引入Nacos，必然需要升级到Alibaba Spring Cloud。想必风险和工作量只增无减。 因此在这样的一个大前提下，我们冒出了“我什么不自己手撸个配置中心”的想法。 配置中心 nadia-config自我打个广告，我的配置中心已经上线了，并且第一版也已经开源，欢迎大家拍砖 https://github.com/nadia-repository/nadia-config","link":"/2020/03/19/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E8%B5%B7%E6%BA%90%E7%AF%87/"},{"title":"搜寻流浪狗APP???","text":"中国AI公司开发了用鼻纹搜索流浪狗的APP如果瞥到流浪狗的海报一定要看看。 随着一个个寒冷的日子，又要到烟花大会的季节。也是家犬被鞭炮声吓跑的季节。 最近家里养狗的越来越多，蹭着窗门开着主人一不留神逃跑的也不在少数，我家的爱犬就是在这个季节逃跑的。 爱犬走丢时一般来说就是张贴寻狗海报或者各处打听。但是中国的一家叫Megvii（旷世）的AI公司可不一样。 根据Verge报道，该公司正在开发一种像人类指纹一样识别狗鼻子形状的【狗识别系统】。使用旷世的APP，通过手机摄像头多角度拍摄狗鼻子就能登录完成。并称具有95%的精度，因此通过这个APP，有1万5000条宠物犬能再和它的主人再会。 但是在中国不是用在和主人的再会，而是和政府合作规范不良狗主人的行为。 具体怎样监视还不清楚，可能是宠物第一次进入家庭的时候登录吧。然后如果想搜寻有问题的狗主人，需要工作人员当场扫描狗鼻子从而鉴别狗主人？ 就我的话还是希望能得到随地大小便的狗狗的主人信息，毕竟家门口落下的便便。。。。。。 本文译自 中川真知子中国のAIスタートアップが迷い犬を鼻の指紋（？）を使って捜索するアプリを開発","link":"/2019/09/06/%E6%90%9C%E5%AF%BB%E6%B5%81%E6%B5%AA%E7%8B%97APP/"},{"title":"自定义配置文件读取&解析","text":"最近开发的项目中遇到了自定义配置文件的读取与解析，结合现有的知识储备设计了一套通用解析方案。 配置文件的结构介绍nadia-proxy的代理配置文件参考了nginx的配置文件，并进行了一定的精简。 123456789101112131415161718192021222324252627282930313233343536373839http { servers { listen 80; location / { root /var/html1; index index.html; } location = /exact { alias /var/html2; } location ^~ /prefix { proxy { strategy ROUND_ROBIN; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } } location ^~ /prefix { proxy { strategy WEIGHTED_ROUND_ROBIN; server 127.0.0.1:8001 weight=1; server 127.0.0.1:8002 weight=2; server 127.0.0.1:8003 weight=3; } } } servers { listen 4321; location / { proxy { strategy IP_HASH; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } } }} 节点 描述 层级 http 配置http协议的代理 0 servers 配置各个服务的代理 1 listen 需要被代理服务对外暴露的端口 2 location 代理服务相关的路径信息 2 root 静态服务代理的文件夹，不包含uri路径 3 alias 静态服务代理的文件夹，包含uri路径 3 index 静态服务代理的默认页面 3 proxy 动态代理的配置信息 3 strategy 动态代理的负载策略，默认为轮训 4 server 动态代理的服务列表 4 如何读取配置文件通过上面的介绍我们可以发现，配置文件是以层级的形式所体现的。为此我们为各个节点设计了数据结构，并已”伙伴“树的形式形成一颗语法书。 配置文件节点的数据结构 123456789enum config_node_type {PARENT,CHILD}; //为合并语法树标识该节点的层级属性typedef struct config_node_struct{ enum config_node_type node_type; void *content; //当前节点的字符串 struct config_node_struct *friend; //同级别的节点 struct config_node_struct *child; //孩子节点} CONFIG_NODE; 文件解析采用自顶向下的解析方式，按照每行逐字符解析字符： 遇到”{“字符时，向配置节点栈中压入一个PARENT类型的节点。 遇到”;”字符时，向配置节点栈中压入一个CHILD类型的节点。 遇到”}”字符时，对之前压入配置节点栈中的节点依次弹出，同为CHILD的节点形成伙伴节点，知道遇到PARENT节点后，将所有的CHILD节点挂载至父节点中，并将PARENT已CHILD节点的身份重新入栈。 重复上述1-3的流程，直至文件解析完成。 节点的语法树解析直至上一个步骤，我们将配置文件读取完成并解析成一颗包含配置信息的语法树。 目前我们无法得知各个节点的具体配置内容及其配置信息，并且也无法得知解析的配置项是否满足我们的配置要求。 为此我们需要一种机制，自动解析并生成我们最终定义的配置数据结构。这里我们采用方式为有限状态机(finite-state machine)。 有限状态机(finite-state machine)有限状态机能很好的将我们需要解析的配置收束至一个我们可控的范围。我们简化了状态机的工作原理，主要采用状态机的状态流转性。已配置语法树的前置遍历来驱动状态机的扭转。 有限状态机的数据结构 1234567891011enum state {INIT,HTTP,SERVERS,LISTEN,LOCATION,ROOT,ALIAS,INDEX,STRATEGY,PROXY,SERVER}; //状态机中的各个状态typedef struct finite_state_machine { enum state current_state; //当前状态 char *tag; //状态名 void *(* parse)(char *line,void *config); //当前状态的执行器 ARRAYLIST *child_state_list; //子状态列表 ARRAYLIST *frient_state_list; //同级状态列表} FSM; 代码实现层面，我们通过”伙伴“树的递归遍历，并依靠状态机的列表来流转状态，最终生成我们需要的配置文件结构。 123456789101112131415161718192021222324 CONFIG_NODE *node = (CONFIG_NODE *)POP_STACK(stack); FSM *init = status_machine_arrary[INIT]; for(int i = 0 ;i &lt; ARRAYLIST_LENGTH(init-&gt;child_state_list) ; i++){ generate_proxy_config(node,nadia_proxy_config,ARRAYLIST_GET(init-&gt;child_state_list,i)); }static void generate_proxy_config(CONFIG_NODE *node, void *config, FSM *fsm){ if(node == NULL){ return; } STRING *string = (STRING *)node-&gt;content; void *node_config = NULL; if(strstr(string-&gt;string,fsm-&gt;tag) != NULL){ node_config = fsm-&gt;parse(string-&gt;string,config); } //parse child for(int i = 0 ;i &lt; ARRAYLIST_LENGTH(fsm-&gt;child_state_list) ; i++){ generate_proxy_config(node-&gt;child,node_config,ARRAYLIST_GET(fsm-&gt;child_state_list,i)); } //parse friend for(int i = 0 ;i &lt; ARRAYLIST_LENGTH(fsm-&gt;frient_state_list) ; i++){ generate_proxy_config(node-&gt;friend,config,ARRAYLIST_GET(fsm-&gt;frient_state_list,i)); }}","link":"/2020/12/11/%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96-%E8%A7%A3%E6%9E%90/"},{"title":"自己动手写Java虚拟机 笔记1","text":"环境配置 安装Golang https://golang.google.cn/ 设置Go环境变量 同时要注意，go的工作目录为该目录，如果需要切换需要改变此路径，不然可使用GoLand等ide切换。 简单实现java命令java SDK自带很多命令，如java、javac、javap等。java命令是其中最终要的一个，平时我们启动一个jar，如springboot工程。还是一个基于tomcat、weblogic、jboss的war包。其根本都是利用java命令执行main方法为入口。 1234java [-options] class [args]java [-options] -jar jarfile [args]javaw [-options] class [args]javaw [-options] -jar jarfile [args] 官方说明： https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html 用Go实现java命令的参数读取 java命令入参结构 12345678type Cmd struct { helpFlag bool //命令为help 或 ? 时：true versionFlag bool //命令是否为version时：true cpOption string //命令为cp 或 classpath时，保存值 XjreOption string //命令为Xjre时，保存值 class string //保存class args []string //保存其他入参} 解析入参 123456789101112131415161718192021func parseCmd() *Cmd { cmd := &amp;Cmd{} //实例化入参对象 flag.Usage = printUsage //设置用法说明 flag.BoolVar(&amp;cmd.helpFlag,&quot;help&quot;,false,&quot;print help message&quot;) //参数为help时，&amp;cmd.helpFlag = true flag.BoolVar(&amp;cmd.helpFlag,&quot;?&quot;,false,&quot;print help message&quot;) //参数为?时，&amp;cmd.helpFlag = true flag.BoolVar(&amp;cmd.versionFlag,&quot;version&quot;,false,&quot;print version and exit&quot;) //参数为version时，&amp;cmd.versionFlag = true flag.StringVar(&amp;cmd.cpOption,&quot;cp&quot;,&quot;&quot;,&quot;classpath&quot;) //参数为version时，&amp;cmd.versionFlag = true flag.StringVar(&amp;cmd.cpOption,&quot;classpath&quot;,&quot;&quot;,&quot;classpath&quot;) flag.StringVar(&amp;cmd.XjreOption,&quot;Xjre&quot;,&quot;&quot;,&quot;path to jres&quot;) flag.Parse() args := flag.Args() if len(args) &gt; 0 { cmd.class = args[0] cmd.args = args[1:] } return cmd}func printUsage() { fmt.Printf(&quot;Usage: %s [-options] class [args...]\\n&quot;,os.Args[0])} 启动方法 1234567891011121314func main () { cmd := parseCmd() //解析方法 if cmd.versionFlag { fmt.Println(&quot;version 0.0.1&quot;) //入参为version时打印版本号 } else if cmd.helpFlag || cmd.class == &quot;&quot; { printUsage() //入参为help或?或classpath、cp为空时打印说明 }else { startJVM(cmd) //启动JVM }}func startJVM(cmd *Cmd){ fmt.Printf(&quot;classpath:%s class:%s args:%v&quot;,cmd.cpOption,cmd.class,cmd.args)} 试运行 12345678910D:\\work\\workspace_go\\src\\jvmgo\\ch01&gt; go installPS D:\\work\\workspace_go\\bin&gt; .\\ch01.exe -versionversion 0.0.1PS D:\\work\\workspace_go\\bin&gt; .\\ch01.exe -helpUsage: D:\\work\\workspace_go\\bin\\ch01.exe [-options] class [args...]PS D:\\work\\workspace_go\\bin&gt; .\\ch01.exe -cp test.class a b cclasspath:test.class class:a args:[b c]","link":"/2019/09/09/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B01/"},{"title":"自己动手写Java虚拟机 笔记2","text":"实现cp/classpath 参数搜索class文件java class path 搜索顺序： 启动类路径（bootstrap classpath）:jre\\lib （可通过-Xbootclasspath参数修改该路径） 扩展类路径（extension classpath）:jre\\lib\\ext 用户类路径（user classpath）:用户自己指定 实现 Entry接口用来定义启动类的基本功能 123456789101112131415161718192021222324const pathListSeparator = string(os.PathListSeparator) //获取当前操作系统分隔符type Entry interface { readClass(classNme string) ([]byte,Entry,error) //定义按class名读取class文件的方 String() string }//根据classpath生成对应的启动类func newEntry(path string) Entry { if strings.Contains(path,pathListSeparator){ //classpath路径包含系统分割符时，new组合启动类 return newCompositeEntry(path) } if strings.HasSuffix(path,&quot;*&quot;) { return newWildcardEntry(path) //classpath路径包含*时，new通配符启动类 } if strings.HasSuffix(path, &quot;.jar&quot;) || strings.HasSuffix(path, &quot;.JAR&quot;) || strings.HasSuffix(path, &quot;.zip&quot;) || strings.HasSuffix(path, &quot;.ZIP&quot;) { return newZipEntry(path) //classpath路径包含jar、JAR、zip、ZIP时，new文件夹启动类 } return newDirEntry(path)} Entry接口的具体实现 DirEntry，按照文件路径读取文件二进制流 12345678910111213141516171819202122type DirEntry struct { absDir string //存储文件夹路径}func newDirEntry(path string) *DirEntry { absDir,err := filepath.Abs(path) //如果文件路径存在，获取文件夹路径 if err != nil { panic(err) //文件路径不存在时提示错误 } return &amp;DirEntry{absDir} //返回DirEntry实例}func (self *DirEntry) readClass(className string) ([]byte,Entry,error){ fileName := filepath.Join(self.absDir,className) //拼接文件夹路径和classname data,err := ioutil.ReadFile(fileName) //读取文件 return data,self,err //返回文件内容}func(self *DirEntry) String() string { return self.absDir //返回文件夹路径} ZipEntry,读取压缩文件夹内的文件 1234567891011121314151617181920212223242526272829303132333435363738type ZipEnty struct { absPath string //文件夹路径}func newZipEntry(path string) *ZipEnty { absPath, err := filepath.Abs(path) //如果文件路径存在，获取文件夹路径 if err != nil { panic(err) } return &amp;ZipEnty{absPath}}func (self *ZipEnty) readClass(className string) ([]byte,Entry,error){ r, err := zip.OpenReader(self.absPath) //以压缩文件格式解压 if err != nil { return nil, nil, err } defer r.Close() //最后关闭文件流 for _, f := range r.File { //循环解压出来的文件 if f.Name == className { //如果当前文件为指定文件 rc, err := f.Open() //打开该文件 if err != nil { return nil, nil, err } defer rc.Close() //最后关闭文件 data, err := ioutil.ReadAll(rc) //读取文件流 if err != nil { return nil, nil, err } return data, self, nil //返回文件流 } } return nil, nil, errors.New(&quot;class not found: &quot; + className)}func (self *ZipEnty) String() string { return self.absPath} CompositeEntry,读取符合文件类型 1234567891011121314151617181920212223242526272829type CompositeEntry []Entry //CompositeEntry为多种Entry的数组（Dir、Zip）func newCompositeEntry(pathList string) CompositeEntry { compositeEntry := []Entry{} //实例Entry接口数组 for _,path := range strings.Split(pathList,pathListSeparator){ //按照系统分割符截取path列表，并循环 entry := newEntry(path) //按照每种path实例化不同的Entry(Dir、Zip、Wildcard) compositeEntry = append(compositeEntry,entry) //将实例化的不同Entry放入CompositeEntry数组中 } return compositeEntry}func (self CompositeEntry) readClass(className string)([]byte,Entry,error){ for _, entry := range self { //循环compositeEntry数组 data, from, err := entry.readClass(className) //根据不同Entry(Dir、Zip、Wildcard)，按指定classname读取文件 if err == nil { return data, from, nil //返回读取结果 } } return nil, nil, errors.New(&quot;class not found: &quot; + className) //无结果是返回错误信息}func (self CompositeEntry) String() string { strs := make([]string, len(self)) //按照CompositeEntry的长度申明该长度的Sring数组 for i, entry := range self { //循环CompositeEntry strs[i] = entry.String() //调用每个Entry(Dir、Zip、Wildcard)实现类的String()方法,并放入String数组中 } return strings.Join(strs, pathListSeparator) //将String数组中的结果以系统分隔符拼接并返回} WildcardEntry，按照通配符解析文件 12345678910111213141516171819func newWildcardEntry(path string) CompositeEntry { baseDir := path[:len(path)-1] // remove * compositeEntry := []Entry{} //申明compositeEntry对象(Entry的数组) walkFn := func(path string, info os.FileInfo, err error) error { if err != nil { return err } if info.IsDir() &amp;&amp; path != baseDir { //如果当前目录是文件夹，并且是根目录 return filepath.SkipDir //返回SkipDir的错误 } if strings.HasSuffix(path, &quot;.jar&quot;) || strings.HasSuffix(path, &quot;.JAR&quot;) { //如果当前路径是以.jar或.JAR结尾的 jarEntry := newZipEntry(path) //实例化ZipEntry compositeEntry = append(compositeEntry, jarEntry) //将实例化的ZipEntry对象放入compositeEntry数组中 } return nil } filepath.Walk(baseDir, walkFn) //将walkFn方法传递给filepath.Walk return compositeEntry //返回结果 } Classpath，-cp|classpath参数解析实现的入口方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566type Classpath struct { //Classpath包含java的三种基础启动路径 bootClasspath Entry extClasspath Entry userClasspath Entry}func Parse(jreOption, cpOption string) * Classpath { cp := &amp;Classpath{} //实例化Classpath对象 cp.parseBootAndExtClasspath(jreOption) //按照-Xjre参数解析Boot和Ext启动路径 cp.parseUserClasspath(cpOption) //按照-cp|classpath参数解析User启动路径 return cp //返回设置好启动路径的Classpath对象}func (self *Classpath) ReadClass(className string) ([]byte,Entry,error){ className = className + &quot;.class&quot; //初始化className文件名 if data, entry, err := self.bootClasspath.readClass(className); err == nil { //先扫描Boot启动路径下是否存在该className.class文件 return data, entry, err //存在则返回 } if data, entry, err := self.extClasspath.readClass(className); err == nil { //再扫描Ext启动路径下是否存在该className.class文件 return data, entry, err //存在则返回 } return self.userClasspath.readClass(className) //以上两个路径下都不存在，则扫描User启动路径}func (self *Classpath) String() string { return self.userClasspath.String()}func (self *Classpath) parseBootAndExtClasspath(jreOption string) { //按照-Xjre参数解析Boot和Ext启动路径 jreDir := getJreDir(jreOption) //获取jre路径 // jre/lib/* jreLibPath := filepath.Join(jreDir, &quot;lib&quot;, &quot;*&quot;) self.bootClasspath = newWildcardEntry(jreLibPath) // jre/lib/ext/* jreExtPath := filepath.Join(jreDir, &quot;lib&quot;, &quot;ext&quot;, &quot;*&quot;) self.extClasspath = newWildcardEntry(jreExtPath)}func getJreDir(jreOption string) string { if jreOption != &quot;&quot; &amp;&amp; exists(jreOption) { //jreOption不为空且存在时返回该路径 return jreOption } if exists(&quot;./jre&quot;) { //./jre路径存在时，返回.jre return &quot;./jre&quot; } if jh := os.Getenv(&quot;JAVA_HOME&quot;); jh != &quot;&quot; { //环境变量JAVA_HOME存在并且不为空时 return filepath.Join(jh, &quot;jre&quot;) //返回JAVA_HOME + &quot;jre&quot; } panic(&quot;Can not find jre folder!&quot;) } func exists(path string) bool { if _, err := os.Stat(path); err != nil { if os.IsNotExist(err) { return false } } return true } func (self *Classpath) parseUserClasspath(cpOption string) { //按照-cp|classpath参数解析User启动参数 if cpOption == &quot;&quot; { //cpOption为空时 cpOption = &quot;.&quot; //返回相对路劲 } self.userClasspath = newEntry(cpOption) //根据-cp|classpath参数实例化对应的Entry } main，修改启动类 123456789101112func startJVM(cmd *Cmd){ cp := classpath.Parse(cmd.XjreOption, cmd.cpOption) //根据-Xjre和-cp|classpath参数实例化classpath对象实例 fmt.Printf(&quot;classpath:%v class:%v args:%v\\n&quot;, cp, cmd.class, cmd.args) className := strings.Replace(cmd.class, &quot;.&quot;, &quot;/&quot;, -1) classData, _, err := cp.ReadClass(className) //按照3个启动路径查找并读取className文件 if err != nil { fmt.Printf(&quot;Could not find or load main class %s\\n&quot;, cmd.class) return } fmt.Printf(&quot;class data:%v\\n&quot;, classData)} 试运行12345678910111213PS D:\\work\\workspace_go\\src\\jvmgo\\ch02&gt; go installPS D:\\work\\workspace_go\\bin&gt; .\\ch02.exe -Xjre &quot;C:\\Program Files\\Java\\jre1.8.0_202&quot; java.lang.Objectclasspath:D:\\work\\workspace_go\\bin class:java.lang.Object args:[]class data:[202 254 186 190 0 0 0 52 0 75 3 0 15 66 63 8 0 16 8 0 36 8 0 40 1 0 3 40 41 73 1 0 20 40 41 76 106 97 118 97 47 108 97 110 103 47 79 98 106 101 99 116 59 1 0 20 40 41 76 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 59 1 0 3 40 41 86 1 0 21 40 73 41 76 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 59 1 0 4 40 74 41 86 1 0 5 40 74 73 41 86 1 0 21 40 76 106 97 118 97 47 108 97 110 103 47 79 98 106 101 99 116 59 41 90 1 0 21 40 76 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 59 41 86 1 0 8 60 99 108 105 110 105 116 62 1 0 6 60 105 110 105 116 62 1 0 1 64 1 0 4 67 111 100101 1 0 10 69 120 99 101 112 116 105 111 110 115 1 0 9 83 105 103 110 97 116 117 114 101 1 0 13 83 116 97 99 107 77 97 112 84 97 98 108 101 1 0 6 97 112 112 101 110 100 1 0 5 99 108 111 110 101 1 0 6 101 113117 97 108 115 1 0 8 102 105 110 97 108 105 122 101 1 0 8 103 101 116 67 108 97 115 115 1 0 7 103 101 116 78 97 109 101 1 0 8 104 97 115 104 67 111 100 101 1 0 15 106 97 118 97 47 108 97 110 103 47 67 108 97115 115 1 0 36 106 97 118 97 47 108 97 110 103 47 67 108 111 110 101 78 111 116 83 117 112 112 111 114 116 101 100 69 120 99 101 112 116 105 111 110 1 0 34 106 97 118 97 47 108 97 110 103 47 73 108 108 101 103 97 108 65 114 103 117 109 101 110 116 69 120 99 101 112 116 105 111 110 1 0 17 106 97 118 97 47 108 97 110 103 47 73 110 116 101 103 101 114 1 0 30 106 97 118 97 47 108 97 110 103 47 73 110 116 101 114 114117 112 116 101 100 69 120 99 101 112 116 105 111 110 1 0 16 106 97 118 97 47 108 97 110 103 47 79 98 106 101 99 116 1 0 23 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 66 117 105 108 100 101 114 1 0 19 106 97 118 97 47 108 97 110 103 47 84 104 114 111 119 97 98 108 101 1 0 37 110 97 110 111 115 101 99 111 110 100 32 116 105 109 101 111 117 116 32 118 97 108 117 101 32 111 117 116 32 111 102 32 114 97 110 103 101 1 0 6 110 111 116 105 102 121 1 0 9 110 111 116 105 102 121 65 108 108 1 0 15 114 101 103 105 115 116 101 114 78 97 116 105 118 101 115 1 0 25 116 105 109 101 111 117 116 32 118 97 108 117 101 32 105 115 32 110 101 103 97 116 105 118 101 1 0 11 116 111 72 101 120 83 116 114 105 110 103 1 0 8 116 111 83 116 114 105 110 103 1 0 4 119 97 105 116 7 0 28 7 0 29 7 0 30 7 0 31 7 0 32 7 0 33 7 0 34 7 0 35 1 0 19 40 41 76 106 97 118 97 47 108 97 110 103 47 67 108 97 115 115 59 1 0 22 40 41 76 106 97 118 97 47 108 97 110 103 47 67 108 97 115 115 60 42 62 59 1 0 45 40 76 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 59 41 76 106 97 118 97 47 108 97 110 103 47 83 116 114 105 110 103 66 117 105 108 100 101 114 59 12 0 27 0 5 12 0 15 0 8 12 0 39 0 8 12 0 43 0 10 12 0 25 0 52 12 0 26 0 7 12 0 42 0 7 12 0 41 09 12 0 15 0 13 12 0 21 0 54 10 0 44 0 60 10 0 46 0 63 10 0 47 0 62 10 0 49 0 55 10 0 49 0 57 10 0 49 0 58 10 0 49 0 59 10 0 50 0 56 10 0 50 0 61 10 0 50 0 64 0 33 0 49 0 0 0 0 0 0 0 14 0 1 0 15 0 8 0 1 0 17 0 0 0 13 0 0 0 1 0 0 0 1 177 0 0 0 0 1 10 0 39 0 8 0 0 1 17 0 25 0 52 0 1 0 19 0 0 0 2 0 53 1 1 0 27 0 5 0 0 0 1 0 23 0 12 0 1 0 17 0 0 0 34 0 2 0 2 0 0 0 11 42 43 166 0 7 4 167 0 4 3 172 0 0 0 1 0 20 0 0 0 50 2 9 64 1 1 4 0 22 0 6 0 1 0 18 0 0 0 4 0 1 0 45 0 1 0 42 0 7 0 1 0 17 0 0 0 48 0 2 0 1 0 0 0 36 187 0 50 89 183 0 72 42 182 0 71 182 0 65 182 0 74 18 2 182 0 74 42 182 0 68 184 0 67 182 0 74 182 0 73 176 00 0 0 1 17 0 37 0 8 0 0 1 17 0 38 0 8 0 0 1 17 0 43 0 10 0 1 0 18 0 0 0 4 0 1 0 48 0 17 0 43 0 11 0 2 0 17 0 0 0 74 0 4 0 4 0 0 0 50 31 9 148 156 0 13 187 0 46 89 18 4 183 0 66 191 29 155 0 9 29 18 1 164 0 13 187 0 46 89 18 3 183 0 66 191 29 158 0 7 31 10 97 64 42 31 182 0 70 177 0 0 0 1 0 20 0 0 0 6 0 4 16 9 9 7 0 18 0 0 0 4 0 1 0 48 0 17 0 43 0 8 0 2 0 17 0 0 0 18 0 3 0 1 0 0 0 6 42 9 182 0 70 177 0 0 0 0 0 180 0 0 4 0 1 0 48 0 4 0 24 0 8 0 2 0 17 0 0 0 13 0 0 0 1 0 0 0 1 177 0 0 0 0 0 18 0 0 0 4 0 1 0 51 0 8 0 14 0 8 0 1 0 17 0 0 0 16 0 0 0 0 0 0 0 4 184 0 69 177 0 0 0 0 0 0]","link":"/2019/09/10/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B02/"},{"title":"自己动手写Java虚拟机 笔记3","text":"第三篇主要学习JVM中class文件的具体结构，和JVM是如何解析这些结构的。我们可以通过javac工具将一个java文件compile成一个.class文件，并通过我们自己写的jvm将该文件解析并打印出来。通过class文件的学习能让我们更加深刻的理解java是怎样实现跨平台，并且我们编写的java代码又是如何在JVM中体现的。 JVM中class文件结构(ClassFile) Length name u4 magic u2 minor_version u2 major_version u2 constant_pool_count cp_info constant_pool[constant_pool_count-1] u2 access_flags u2 this_class u2 super_class u2 interfaces_count u2 interfaces[interfaces_count] u2 fields_count field_info fields[fields_count] u2 methods_count method_info methods[methods_count] JVM中字段结构(field_info) Length name u2 access_flags u2 name_index u2 descriptor_index u2 attributes_count attribute_info attributes[attributes_count] JVM中访问控制符结构(access_flags) 标志名 标志值 标志含义 针对的对象 ACC_PUBLIC 0x0001 public类型 所有类型 ACC_FINAL 0x0010 final类型 类 ACC_SUPER 0x0020 使用新的invokespecial语义 类和接口 ACC_INTERFACE 0x0200 接口类型 接口 ACC_ABSTRACT 0x0400 抽象类型 类和接口 ACC_SYNTHETIC 0x1000 该类不由用户代码生成 所有类型 ACC_ANNOTATION 0x2000 注解类型 注解 ACC_ENUM 0x4000 枚举类型 枚举 实现 定义Class文件的录取类(ClassReader) 123456789101112131415161718192021222324252627282930313233343536373839404142434445type ClassReader struct { data []byte //class文件字节流}// 读取u1func (self *ClassReader) readUint8() uint8 { val := self.data[0] //读取1Byte self.data = self.data[1:] return val}// u2func (self *ClassReader) readUint16() uint16 { val := binary.BigEndian.Uint16(self.data) //读取2Byte并转为uint16 self.data = self.data[2:] return val}// u4func (self *ClassReader) readUint32() uint32 { val := binary.BigEndian.Uint32(self.data) //读取4Byte并转为uint32 self.data = self.data[4:] return val}func (self *ClassReader) readUint64() uint64 { val := binary.BigEndian.Uint64(self.data) //读取8Byte并转为uint64 self.data = self.data[8:] return val}func (self *ClassReader) readUint16s() []uint16 { n := self.readUint16() //读取2Byte，该值为后续数组的长度 s := make([]uint16, n) //生产长度为n的uint16类型数组 for i := range s { s[i] = self.readUint16() //读取class文件，每读取2Byte便放入数组 } return s}func (self *ClassReader) readBytes(n uint32) []byte { bytes := self.data[:n] //读取长度为n的字节 self.data = self.data[n:] return bytes} 定义Class文件的格式(ClassFile) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111type ClassFile struct { //按照jvm规范，定义class文件结构 //magic uint32 minorVersion uint16 majorVersion uint16 constantPool ConstantPool accessFlags uint16 thisClass uint16 superClass uint16 interfaces []uint16 fields []*MemberInfo methods []*MemberInfo attributes []AttributeInfo}//文件解析入口方法，入参class文件流，返回class文件对象func Parse(classData []byte) (cf *ClassFile, err error) { defer func() { //捕获异常 if r := recover(); r != nil { var ok bool err, ok = r.(error) if !ok { err = fmt.Errorf(&quot;%v&quot;, r) } } }() cr := &amp;ClassReader{classData} //实例化classReader类 cf = &amp;ClassFile{} //实例化ClassFile类 cf.read(cr) //读取class文件 return}//读取class文件的具体方法func (self *ClassFile) read(reader *ClassReader) { self.readAndCheckMagic(reader) //读取魔数 self.readAndCheckVersion(reader) //读取主次版本号 self.constantPool = readConstantPool(reader) //读取常量池 self.accessFlags = reader.readUint16() //读取当前类（或者接口）的访问修饰符 self.thisClass = reader.readUint16() //读取当前类索引 self.superClass = reader.readUint16() //读取父类索引 self.interfaces = reader.readUint16s() //读取所有接口索引 self.fields = readMembers(reader, self.constantPool) //从常量池中读取所有成员 self.methods = readMembers(reader, self.constantPool) //从常量池中读取所有方法 self.attributes = readAttributes(reader, self.constantPool) //从常量池中读取所有属性}func (self *ClassFile) readAndCheckMagic(reader *ClassReader) { magic := reader.readUint32() //读取4Byte魔数 if magic != 0xCAFEBABE { //判断魔数是否为0xCAFEBABE panic(&quot;java.lang.ClassFormatError: magic!&quot;) }}func (self *ClassFile) readAndCheckVersion(reader *ClassReader) { self.minorVersion = reader.readUint16() //高2Byte为次版本号 self.majorVersion = reader.readUint16() //低2Byte为主版本号 switch self.majorVersion { //检查版本号是否为45~52 case 45: return case 46, 47, 48, 49, 50, 51, 52: if self.minorVersion == 0 { return } } panic(&quot;java.lang.UnsupportedClassVersionError!&quot;)}//对外暴露get方法func (self *ClassFile) MinorVersion() uint16 { return self.minorVersion}//对外暴露get方法func (self *ClassFile) MajorVersion() uint16 { return self.majorVersion}//对外暴露get方法func (self *ClassFile) ConstantPool() ConstantPool { return self.constantPool}//对外暴露get方法func (self *ClassFile) AccessFlags() uint16 { return self.accessFlags}//对外暴露get方法func (self *ClassFile) Fields() []*MemberInfo { return self.fields}//对外暴露get方法func (self *ClassFile) Methods() []*MemberInfo { return self.methods}//对外暴露get方法，根据thisClass索引在常量池中查找名称func (self *ClassFile) ClassName() string { return self.constantPool.getClassName(self.thisClass)}//对外暴露get方法，根据superClass索引在常量池中查找名称func (self *ClassFile) SuperClassName() string { if self.superClass &gt; 0 { return self.constantPool.getClassName(self.superClass) } return &quot;&quot;}//对外暴露get方法，根据interfaces索引在常量池中查找名称func (self *ClassFile) InterfaceNames() []string { interfaceNames := make([]string, len(self.interfaces)) for i, cpIndex := range self.interfaces { interfaceNames[i] = self.constantPool.getClassName(cpIndex) } return interfaceNames} 定义字段和方法的结构(field_info、method_info) 123456789101112131415161718192021222324252627282930313233343536373839404142type MemberInfo struct { //field和method的结构类型，使用同一个结构 cp ConstantPool //当前常量池 accessFlags uint16 //访问标志 nameIndex uint16 //名称索引 descriptorIndex uint16 //描述索引 attributes []AttributeInfo //属性列表 }// read field or method tablefunc readMembers(reader *ClassReader, cp ConstantPool) []*MemberInfo { memberCount := reader.readUint16() //读取field或method数量 members := make([]*MemberInfo, memberCount) //创建数组 for i := range members { members[i] = readMember(reader, cp) } return members}//具体读取field和method的方法func readMember(reader *ClassReader, cp ConstantPool) *MemberInfo { return &amp;MemberInfo{ cp: cp, accessFlags: reader.readUint16(), //读取2Byte的访问控制符 nameIndex: reader.readUint16(), //读取2Byte的名称索引 descriptorIndex: reader.readUint16(), //读取2Byte的描述索引 attributes: readAttributes(reader, cp), //读取属性列表 }}//对外暴露get方法func (self *MemberInfo) AccessFlags() uint16 { return self.accessFlags}//对外暴露get方法，通过名称索引访问常量池func (self *MemberInfo) Name() string { return self.cp.getUtf8(self.nameIndex)}//对外暴露get方法，通过描述索引访问常量池func (self *MemberInfo) Descriptor() string { return self.cp.getUtf8(self.descriptorIndex)}","link":"/2019/09/13/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B03/"},{"title":"自己动手写Java虚拟机 笔记4","text":"运行时数据区JVM将需要用到的数据存放入内存中，这个内存区就叫运行时数据区可分为两种： 一类是多线程共享的，该数据区需要在Java虚拟机启动时创建好，在Java虚拟机退出时销毁。 一类则是线程私有的，该数据区则在创建线程时才创建，线程退出时销毁。 实现定义对象结构1234type Object struct { // todo} 运行时数据区-线程12345678910111213141516171819202122232425262728293031323334353637type Thread struct { pc int // the address of the instruction currently being executed stack *Stack //Java虚拟机栈指针 // todo}//创建Thread实例//java命令提供了-Xss选项来设置Java虚拟机栈大小func NewThread() *Thread { return &amp;Thread{ stack: newStack(1024), //最多容纳1024帧 }}func (self *Thread) PC() int { return self.pc}func (self *Thread) SetPC(pc int) { self.pc = pc}//当前帧进栈func (self *Thread) PushFrame(frame *Frame) { self.stack.push(frame)}//当前帧出栈func (self *Thread) PopFrame() *Frame { return self.stack.pop()}//获取当前帧func (self *Thread) CurrentFrame() *Frame { return self.stack.top()} 运行时数据区-Java虚拟机栈1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950type Stack struct { maxSize uint //最多可以容纳多少帧 size uint //栈的当前大小 _top *Frame //保存栈顶指针}//实例一个栈func newStack(maxSize uint) *Stack { return &amp;Stack{ maxSize: maxSize, }}//当前帧进栈func (self *Stack) push(frame *Frame) { if self.size &gt;= self.maxSize { //判断当前栈大小是否超过最大容量 panic(&quot;java.lang.StackOverflowError&quot;) } if self._top != nil { //当前栈顶不为空时 frame.lower = self._top //将插入帧尾指向栈顶指针 } self._top = frame //当前栈顶指向当前帧 self.size++ //当前栈大小加1}//当前帧出栈func (self *Stack) pop() *Frame { if self._top == nil { //当前栈顶为空时报错 panic(&quot;jvm stack is empty!&quot;) } top := self._top //取出当前栈顶帧 self._top = top.lower //将当前栈顶指向top的下一帧 top.lower = nil //断开top的尾指针 self.size-- //当前栈大小减1 return top //返回top}//获取当前栈顶帧func (self *Stack) top() *Frame { if self._top == nil { ////当前栈顶为空时报错 panic(&quot;jvm stack is empty!&quot;) } return self._top //返回当前栈顶帧} 运行时数据区-帧1234567891011121314151617181920212223type Frame struct { lower *Frame //指向下一帧 localVars LocalVars //保存局部变量表指针 operandStack *OperandStack //保存操作数栈指针 // todo}//实例化帧func NewFrame(maxLocals, maxStack uint) *Frame { return &amp;Frame{ localVars: newLocalVars(maxLocals), //实例化局部变量对象 operandStack: newOperandStack(maxStack), //实例化操作数栈对象 }}// gettersfunc (self *Frame) LocalVars() LocalVars { return self.localVars}func (self *Frame) OperandStack() *OperandStack { return self.operandStack} 运行时数据区-局部变量表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960type LocalVars []Slot//创建局部变量实例func newLocalVars(maxLocals uint) LocalVars { if maxLocals &gt; 0 { return make([]Slot, maxLocals) //申明大小为maxLocals的Slot数组 } return nil}//设置int类型func (self LocalVars) SetInt(index uint, val int32) { self[index].num = val}//取int类型func (self LocalVars) GetInt(index uint) int32 { return self[index].num}//设置float32类型func (self LocalVars) SetFloat(index uint, val float32) { bits := math.Float32bits(val)//转为uint32 self[index].num = int32(bits) //转为int32}//取float32类型func (self LocalVars) GetFloat(index uint) float32 { bits := uint32(self[index].num)//转为unit32 return math.Float32frombits(bits)//转为float}//设置long类型func (self LocalVars) SetLong(index uint, val int64) { self[index].num = int32(val)//取低位32位存储在index self[index+1].num = int32(val &gt;&gt; 32) //右移32位取高位32位存储在index+1}//取long类型func (self LocalVars) GetLong(index uint) int64 { low := uint32(self[index].num) //取index低32位 high := uint32(self[index+1].num) //取index+1高32位 return int64(high)&lt;&lt;32 | int64(low) //左移高位32位，拼接高低位返回}//设置float64func (self LocalVars) SetDouble(index uint, val float64) { bits := math.Float64bits(val) //转为uint64 self.SetLong(index, int64(bits)) //用long型设置方法设置int64}//取float64func (self LocalVars) GetDouble(index uint) float64 { bits := uint64(self.GetLong(index)) //按long型取值方法取出uint64 return math.Float64frombits(bits) //转为float64}//设置引用func (self LocalVars) SetRef(index uint, ref *Object) { self[index].ref = ref}//取引用func (self LocalVars) GetRef(index uint) *Object { return self[index].ref} 运行时数据区-操作数栈12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667type OperandStack struct { size uint //记录栈顶位置 slots []Slot}//实例化操作数栈func newOperandStack(maxStack uint) *OperandStack { if maxStack &gt; 0 { return &amp;OperandStack{ slots: make([]Slot, maxStack),//申明maxStack大小的Slot数组 } } return nil}func (self *OperandStack) PushInt(val int32) { self.slots[self.size].num = val self.size++}func (self *OperandStack) PopInt() int32 { self.size-- return self.slots[self.size].num}func (self *OperandStack) PushFloat(val float32) { bits := math.Float32bits(val) self.slots[self.size].num = int32(bits) self.size++}func (self *OperandStack) PopFloat() float32 { self.size-- bits := uint32(self.slots[self.size].num) return math.Float32frombits(bits)}// long consumes two slotsfunc (self *OperandStack) PushLong(val int64) { self.slots[self.size].num = int32(val) self.slots[self.size+1].num = int32(val &gt;&gt; 32) self.size += 2}func (self *OperandStack) PopLong() int64 { self.size -= 2 low := uint32(self.slots[self.size].num) high := uint32(self.slots[self.size+1].num) return int64(high)&lt;&lt;32 | int64(low)}// double consumes two slotsfunc (self *OperandStack) PushDouble(val float64) { bits := math.Float64bits(val) self.PushLong(int64(bits))}func (self *OperandStack) PopDouble() float64 { bits := uint64(self.PopLong()) return math.Float64frombits(bits)}func (self *OperandStack) PushRef(ref *Object) { self.slots[self.size].ref = ref self.size++}func (self *OperandStack) PopRef() *Object { self.size-- ref := self.slots[self.size].ref self.slots[self.size].ref = nil return ref} 运行时数据区-操作数栈1","link":"/2019/09/26/%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%86%99Java%E8%99%9A%E6%8B%9F%E6%9C%BA-%E7%AC%94%E8%AE%B04/"},{"title":"记一次序列化失败导致的生产问题","text":"文件上传下载时出现以下错误： 经过调查,由于重写了WebMvcConfigurationSupport.configureMessageConverters方法 12345678910111213141516171819202122232425262728293031323334353637@Configurationpublic class OpenServiceConfig extends WebMvcConfigurationSupport implements ApplicationRunner { @Autowired private Environment environment; private ApiMappingHandlerMapping apiMappingHandlerMapping = new ApiMappingHandlerMapping(); @Override protected RequestMappingHandlerMapping createRequestMappingHandlerMapping() { return apiMappingHandlerMapping; } @Override public void run(ApplicationArguments args) { ApiMetaManager apiMetaManager = new ServiceZookeeperApiMetaManager(environment); RequestMappingEvent requestMappingEvent = new DefaultRequestMappingEvent(apiMetaManager, environment); requestMappingEvent.onRegisterSuccess(apiMappingHandlerMapping); } @Override public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) { converters.clear(); ObjectMapper objectMapper = new ObjectMapper().setSerializationInclusion(JsonInclude.Include.NON_NULL); objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES,false); converters.add(new MappingJackson2HttpMessageConverter(objectMapper)); } @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;swagger-ui.html&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/&quot;); registry.addResourceHandler(&quot;/webjars/**&quot;) .addResourceLocations(&quot;classpath:/META-INF/resources/webjars/&quot;); }} springMVC开始加载转换器的时候会先走用户定制化方法 1234567891011protected final List&lt;HttpMessageConverter&lt;?&gt;&gt; getMessageConverters() { if (this.messageConverters == null) { this.messageConverters = new ArrayList&lt;HttpMessageConverter&lt;?&gt;&gt;(); configureMessageConverters(this.messageConverters); if (this.messageConverters.isEmpty()) { addDefaultHttpMessageConverters(this.messageConverters); } extendMessageConverters(this.messageConverters); } return this.messageConverters;} 如果用户没有定制化，springmvc会使用自定个的7个转换器 12345678910111213141516171819202122232425262728293031protected final void addDefaultHttpMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters) { StringHttpMessageConverter stringConverter = new StringHttpMessageConverter(); stringConverter.setWriteAcceptCharset(false); messageConverters.add(new ByteArrayHttpMessageConverter()); messageConverters.add(stringConverter); messageConverters.add(new ResourceHttpMessageConverter()); messageConverters.add(new SourceHttpMessageConverter&lt;Source&gt;()); messageConverters.add(new AllEncompassingFormHttpMessageConverter()); if (romePresent) { messageConverters.add(new AtomFeedHttpMessageConverter()); messageConverters.add(new RssChannelHttpMessageConverter()); } if (jackson2XmlPresent) { messageConverters.add(new MappingJackson2XmlHttpMessageConverter( Jackson2ObjectMapperBuilder.xml().applicationContext(this.applicationContext).build())); } else if (jaxb2Present) { messageConverters.add(new Jaxb2RootElementHttpMessageConverter()); } if (jackson2Present) { messageConverters.add(new MappingJackson2HttpMessageConverter( Jackson2ObjectMapperBuilder.json().applicationContext(this.applicationContext).build())); } else if (gsonPresent) { messageConverters.add(new GsonHttpMessageConverter()); }} 由于项目在自定义的时候没有考虑到文件上传下载这种字节流的解析，导致序列化失败增加配置解决问题 1objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);","link":"/2019/09/24/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%BA%8F%E5%88%97%E5%8C%96%E5%A4%B1%E8%B4%A5%E5%AF%BC%E8%87%B4%E7%9A%84%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98/"},{"title":"🐇","text":"大白兔。。你变了。。。","link":"/2019/09/05/%F0%9F%90%87/"},{"title":"fastjson序列化异常排查","text":"fastjson作为一个轻量级的java序列化类库，其最大的优势就是快，因此也被国内各个中小型公司大量的使用。但它也有不少短板，如可定制性低、API不够丰富、代码质量及文档缺失等一些列问题一直被人所诟病。 本次我们碰到的问题就是由fastjson的一个简单bug而引起的一连串研究。 发现bug某日一位同学在调试新需求的时候发现如下错误日志： 1234567891011121314151617181920Exception in thread &quot;collection-eventbus-thread-1&quot; java.lang.NoSuchMethodError: com.alibaba.fastjson.serializer.JavaBeanSerializer.processValue(Lcom/alibaba/fastjson/serializer/JSONSerializer;Lcom/alibaba/fastjson/serializer/BeanContext;Ljava/lang/Object;Ljava/lang/String;Ljava/lang/Object;)Ljava/lang/Object;Ljava/lang/Integer; at com.alibaba.fastjson.serializer.ASMSerializer_6_FastJsonSerializerWrapper.writeNormal(Unknown Source) at com.alibaba.fastjson.serializer.ASMSerializer_6_FastJsonSerializerWrapper.write(Unknown Source) at com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:285) at com.alibaba.fastjson.JSON.toJSONString(JSON.java:663) at com.alibaba.fastjson.JSON.toJSONString(JSON.java:652) at com.oriente.cache.layeringCache.serializer.FastJsonRedisSerializer.serialize(FastJsonRedisSerializer.java:37) at org.springframework.data.redis.core.AbstractOperations.rawValue(AbstractOperations.java:117) at org.springframework.data.redis.core.DefaultValueOperations.multiSet(DefaultValueOperations.java:136) at com.oriente.collection.event.listener.RedisEventListener.schedule(RedisEventListener.java:75) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.google.common.eventbus.Subscriber.invokeSubscriberMethod(Subscriber.java:87) at com.google.common.eventbus.Subscriber$SynchronizedSubscriber.invokeSubscriberMethod(Subscriber.java:144) at com.google.common.eventbus.Subscriber$1.run(Subscriber.java:72) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 通过观察错误，很快就能定位到是fastjson序列化的时候出现了错误。同时我们也确认的代码，在自定的RedisTemplate中，针对Value的序列化工具我们的确使用了fastjson的序列化方式。 RedisTemplate使用自定义的fastjoson序列化工具 123FastJsonRedisSerializer&lt;Object&gt; fastJsonRedisSerializer = new FastJsonRedisSerializer&lt;&gt;(Object.class);redisTemplate.setValueSerializer(fastJsonRedisSerializer); FastJsonRedisSerializer中使用fastjson的API对统一包装类进行序列化 12345678910@Overridepublic byte[] serialize(T t) throws SerializationException { try { return JSON.toJSONString(new FastJsonSerializerWrapper(t), SerializerFeature.WriteClassName).getBytes(DEFAULT_CHARSET); } catch (Exception e) { throw new SerializationException(String.format(&quot;FastJsonRedisSerializer 序列化异常: %s, 【JSON：%s】&quot;, e.getMessage(), JSON.toJSONString(t)), e); }} 分析bug经过上面的一顿排查，问题已经很明确定位到是fastjson上了，并且错误信息给的相当明确： java.lang.NoSuchMethodError: com.alibaba.fastjson.serializer.JavaBeanSerializer.processValue(Lcom/alibaba/fastjson/serializer/JSONSerializer;Lcom/alibaba/fastjson/serializer/BeanContext;Ljava/lang/Object;Ljava/lang/String;Ljava/lang/Object;)Ljava/lang/Object;Ljava/lang/Integer; 提示未找到JavaBeanSerializer.processValue方法。ok我们立马查询JavaBeanSerializer源码，发现processalue方法是继承自SerializeFilterable类： 方法清单：com.alibaba.fastjson.serializer.JavaBeanSerializer 123456protected Object processValue(JSONSerializer jsonBeanDeser, // BeanContext beanContext, Object object, // String key, // Object propertyValue, // int features) { 乍一看方法是存在的，这是我们又回到了错误本身。仔细查看错误，错误中提示我们processValue方法签名如下： 入参： Lcom/alibaba/fastjson/serializer/JSONSerializer –JSONSerializer类型的对象 Lcom/alibaba/fastjson/serializer/BeanContext –BeanContext类型的对象 Ljava/lang/Object –Object对象 Ljava/lang/String –String 类型 Ljava/lang/Object –Object对象 返回参数： Ljava/lang/Object;Ljava/lang/Integer; –这是什么鬼？java的返回参数应该是不支持两个才对啊！ 经过对比，果然方法签名不一致。源码中SerializeFilterable.processValue()方法中有6个入参，而错误日志中提示的只有5个入参。缺少了最后一个 int features 问题1从方法签名的对比我们可以发现，该错误的确是因为找不对对应的方法所导致的。由于fastjson序列化的对象是通过ASM动态生成字节码产生的，我们可以通多源码或者借助工具来验证这个bug的真实性。 1.代码验证fastjson在java平台下会默认使用ASM的方式动态生成序列化代理类 方法清单：com.alibaba.fastjson.serializer.SerializeConfig 1private boolean asm = !ASMUtils.IS_ANDROID; 方法清单：com.alibaba.fastjson.serializer.SerializeConfig 123456789101112131415161718192021if (asm) { try { ObjectSerializer asmSerializer = createASMSerializer(beanInfo); if (asmSerializer != null) { return asmSerializer; } } catch (ClassNotFoundException ex) { // skip } catch (ClassFormatError e) { // skip } catch (ClassCastException e) { // skip } catch (OutOfMemoryError e) { if (e.getMessage().indexOf(&quot;Metaspace&quot;) != -1) { throw e; } // skip } catch (Throwable e) { throw new JSONException(&quot;create asm serializer error, verson &quot; + JSON.VERSION + &quot;, class &quot; + clazz, e); }} 方法清单：com.alibaba.fastjson.serializer.ASMSerializerFactory 12345678910private void _processValue(MethodVisitor mw, FieldInfo fieldInfo, Context context, Label _end) {... mw.visitMethodInsn(INVOKEVIRTUAL, JavaBeanSerializer, &quot;processValue&quot;, &quot;(L&quot; + JSONSerializer + &quot;;&quot; // + desc(BeanContext.class) // + &quot;Ljava/lang/Object;Ljava/lang/String;&quot; // + valueDesc + &quot;)Ljava/lang/Object;Ljava/lang/Integer;&quot;); ...} 通过上述源码，可以发现在通过ASM生成processValue方法签名时，只定义了5个参数。同时也能看到返回参数多设置了个Ljava/lang/Integer类型。 依赖代码阅读，我们已经可以确定错误代码的位置了。但由于毕竟是通过ASM动态字节码生成的类和对象，实际在JVM中的类是否也像我们现在看到的一样的话，我们就需要借助其他工具来帮助我们观察了。 2.通过HSDB观察JVM中的类 已Debug模式启动Java服务 将断点设置到代理类生产逻辑后 方法清单：com.alibaba.fastjson.serializer.ASMSerializerFactory 1234//将动态生成的字节码对象装维字节数组byte[] code = cw.toByteArray();//动态加载类Class&lt;?&gt; serializerClass = classLoader.defineClassPublic(classNameFull, code, 0, code.length); 打开HSDB 1java -cp sa-jdi.jar sun.jvm.hotspot.HSDB 获取当前java进程 HSDB attach当前java进程 执行方法至断点处后，在HSDB搜索代理类 通过观察FastJsonSerializerWrapper.writeNormal()方法的字节码也可以发现，在调用processValue()方法的时候缺少了一个参数。 查看FastJsonSerializerWrapper的常量池 查看常量池中的内容，也再次确认了processValue()方法的签名存在问题：入参不对、返回参数也有问题。 问题2ASMSerializer_6_FastJsonSerializerWrapper.processValue()方法的返回值有两个。这会带来什么问题？为什么在类动态加载的时候JVM没有检查出方法签名的问题? 预知大道，必先为史。java也一样，java的历史就是JVM。要想了解动态加载类的时候到底做了什么，我们就必须参阅JVM源码。 之前阅读fastjson源码的时候，我们曾经来到这么一段代码。 显然源码是通过调用native方法，将类的字节流写入到JVM中的。jdk为开发者提供了丰富的类加载机制，但究其源还是依赖了这三个native方法，并且这三个方法仅仅是入参不同，其背后的实现原理其实是一样的。 方法清单：java.lang.ClassLoader 123456789private native Class&lt;?&gt; defineClass0(String name, byte[] b, int off, int len, ProtectionDomain pd);private native Class&lt;?&gt; defineClass1(String name, byte[] b, int off, int len, ProtectionDomain pd, String source);private native Class&lt;?&gt; defineClass2(String name, java.nio.ByteBuffer b, int off, int len, ProtectionDomain pd, String source); java native 方法入口按照jni的定义规范，native方法会按照以下的格式进行定义：__JNIEXPORT jclass JNICALL Java_packagepath(包路径已分割)方法名 根据上面的规定，我们很快就能还原出defineClass1方法在jdk中的定义： JNIEXPORT jclass JNICALL Java_java_lang_ClassLoader_defineClass1 代码清单：src/share/native/java/lang/ClassLoader.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475JNIEXPORT jclass JNICALLJava_java_lang_ClassLoader_defineClass1(JNIEnv *env, jobject loader, jstring name, jbyteArray data, jint offset, jint length, jobject pd, jstring source){ jbyte *body; char *utfName; jclass result = 0; char buf[128]; char* utfSource; char sourceBuf[1024]; if (data == NULL) { JNU_ThrowNullPointerException(env, 0); return 0; } /* Work around 4153825. malloc crashes on Solaris when passed a * negative size. */ if (length &lt; 0) { JNU_ThrowArrayIndexOutOfBoundsException(env, 0); return 0; } body = (jbyte *)malloc(length); if (body == 0) { JNU_ThrowOutOfMemoryError(env, 0); return 0; } (*env)-&gt;GetByteArrayRegion(env, data, offset, length, body); if ((*env)-&gt;ExceptionOccurred(env)) goto free_body; if (name != NULL) { utfName = getUTF(env, name, buf, sizeof(buf)); if (utfName == NULL) { JNU_ThrowOutOfMemoryError(env, NULL); goto free_body; } VerifyFixClassname(utfName); } else { utfName = NULL; } if (source != NULL) { utfSource = getUTF(env, source, sourceBuf, sizeof(sourceBuf)); if (utfSource == NULL) { JNU_ThrowOutOfMemoryError(env, NULL); goto free_utfName; } } else { utfSource = NULL; } result = JVM_DefineClassWithSource(env, utfName, loader, body, length, pd, utfSource); if (utfSource &amp;&amp; utfSource != sourceBuf) free(utfSource); free_utfName: if (utfName &amp;&amp; utfName != buf) free(utfName); free_body: free(body); return result;} 代码中调用了JVM_DefineClassWithSource方法，该方法定义在JVM源码中，下载JVM源码搜索该方法。 代码清单：src/share/vm/prims/jvm.cpp 12345JVM_ENTRY(jclass, JVM_DefineClassWithSource(JNIEnv *env, const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd, const char *source)) JVMWrapper2(&quot;JVM_DefineClassWithSource %s&quot;, name); return jvm_define_class_common(env, name, loader, buf, len, pd, source, true, THREAD);JVM_END 经过一连串的内部调用,JVM才开始真正解析字节码流： src/share/vm/prims/jvm.cpp –&gt; JVM_DefineClassWithSource() src/share/vm/prims/jvm.cpp –&gt; jvm_define_class_common() src/share/vm/classfile/systemDictionary.cpp –&gt; Klass* SystemDictionary::resolve_from_stream() src/share/vm/classfile/classFileParser.cpp –&gt; instanceKlassHandle ClassFileParser::parseClassFile() JVM首先会判断是否需要进行格式校验 代码清单：src/share/vm/classfile/classFileParser.cpp 12345678910// Figure out whether we can skip format checking (matching classic VM behavior)if (DumpSharedSpaces) { // verify == true means it&apos;s a &apos;remote&apos; class (i.e., non-boot class) // Verification decision is based on BytecodeVerificationRemote flag // for those classes. _need_verify = (verify) ? BytecodeVerificationRemote : BytecodeVerificationLocal;} else { _need_verify = Verifier::should_verify_for(class_loader(), verify);} DumpSharedSpaces默认为false，因此会走到下面的分支 代码清单：src/share/vm/classfile/verifier.cpp 1234bool Verifier::should_verify_for(oop class_loader, bool should_verify_class) { return (class_loader == NULL || !should_verify_class) ? BytecodeVerificationLocal : BytecodeVerificationRemote;} 当前class_loader为当前classLoad，并且should_verify_class在调用jvm_define_class_common方法时传值true 代码清单：src/share/vm/prims/jvm.cpp 12345JVM_ENTRY(jclass, JVM_DefineClassWithSource(JNIEnv *env, const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd, const char *source)) JVMWrapper2(&quot;JVM_DefineClassWithSource %s&quot;, name); return jvm_define_class_common(env, name, loader, buf, len, pd, source, true, THREAD);JVM_END 因此判断_need_verify的结果最终落到了BytecodeVerificationRemote上。 我们先看BytecodeVerificationRemote在jvm里的定义： 代码清单：src/share/vm/runtime/globals.hpp 12product(bool, BytecodeVerificationRemote, true, \\ &quot;Enable the Java bytecode verifier for remote classes&quot;) \\ 可见BytecodeVerificationRemote在JVM初始化的时候默认值为true，代表非JVM自己的对象在加载的时候需要进行各种校验。 为了证明这点，我们再看看解析方法时具体的逻辑： 代码清单：src/share/vm/classfile/classFileParser.cpp –&gt; methodHandle ClassFileParser::parse_method() 1234567if (_need_verify) { args_size = ((flags &amp; JVM_ACC_STATIC) ? 0 : 1) + verify_legal_method_signature(name, signature, CHECK_(nullHandle)); if (args_size &gt; MAX_ARGS_SIZE) { classfile_parse_error(&quot;Too many arguments in method signature in class file %s&quot;, CHECK_(nullHandle)); }} JVM在解析方法的逻辑中，会先对方法的合法性做各种校验。其中就有对方法签名的校验。如果_need_verify为false，则改校验会被跳过。 通过上面的一连串的代码分析，我们得到了BytecodeVerificationRemote的值最终会影响Fastjson通过ASM动态字节码生成的类文件的解析。 接下来我们搞明白BytecodeVerificationRemote的值是如何被更改的，老样子代码一顿乱搜： 代码清单：src/share/vm/runtime/arguments.cpp –&gt; jint Arguments::parse_each_vm_init_arg 1234567891011121314// -Xverify } else if (match_option(option, &quot;-Xverify&quot;, &amp;tail)) { if (strcmp(tail, &quot;:all&quot;) == 0 || strcmp(tail, &quot;&quot;) == 0) { FLAG_SET_CMDLINE(bool, BytecodeVerificationLocal, true); FLAG_SET_CMDLINE(bool, BytecodeVerificationRemote, true); } else if (strcmp(tail, &quot;:remote&quot;) == 0) { FLAG_SET_CMDLINE(bool, BytecodeVerificationLocal, false); FLAG_SET_CMDLINE(bool, BytecodeVerificationRemote, true); } else if (strcmp(tail, &quot;:none&quot;) == 0) { FLAG_SET_CMDLINE(bool, BytecodeVerificationLocal, false); FLAG_SET_CMDLINE(bool, BytecodeVerificationRemote, false); } else if (is_bad_option(option, args-&gt;ignoreUnrecognized, &quot;verification&quot;)) { return JNI_EINVAL; } Xverify BytecodeVerificationLocal BytecodeVerificationRemote all 或 不传 true true remote false true none false false 顺着这个思路我们再看看服务启动时的参数。由于是采用IDEA启动的springboot项目，我们没有手动指定各种启动参数。老样子我们还是借助其他工具进行查看。这次我们使用jdk自带的VisualVM。 这回事真相大白了，通过IDEA默认启动springboot项目时，会默认带上-Xverify:none参数。结合我们上面对JVM源码的分析，在Xverify==none时。加载类模板时不会对类结构的合法性进行校验，这也最终导致了为什么方法签名明明不正确，但是JVM还是成功的加载了这个类。 至于为什么IDEA启动的时候会带上-Xverify:none参数，我们可以参考官网的一句话。 https://www.jetbrains.com/help/idea/run-debug-configuration-spring-boot.html#configuration-tab 总结至此，整个fastjson序列化引起的异常已经排查完了。 回顾整个排查过程其实这一个错误引出了两个问题。 第一个问题是fastjson通过ASM生成字节码文件的时候，processValue的参数个数不对。fastjson官方在后续版本中增加了processValue的重载方法，从而修复这个问题。 第二个问题是processValue方法的方法签名不正确，方法返回类型写有两个参数。从而引起对JVM解析类时，方法签名合法性校验机制的研究。官方也在后续版本中修正了方法签名的错误。 以上，虽然这次问题的发现和解决都很简单。但是牵扯出了一部分JVM源码的知识，借由这次机会，加深相关知识。","link":"/2020/08/17/fastjson%E5%BA%8F%E5%88%97%E5%8C%96%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/"},{"title":"我为什么会手撸一个配置中心-代码篇","text":"上期我们确定了以Spring的方向和采用Redis来做配置关系，我们就开始围绕这两个大头具体的开始设计客户端功能。 1.让Spring启动我们的配置中心客户端我们定义了配置中心的启动注解。同大多数Spring的整合项目一样，不仅能通过启动注解启用功能，同时还能对配置的应用进行初始设定。 12345678910111213141516171819@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(ConfigRegistrar.class)public @interface EnableNadiaConfig { //启用环境 //未设置时所有环境启动 String[] actives() default {}; //指定配置所属的Application String application() default &quot;&quot;; //默认分组 //未设置时为默认分组 String group() default &quot;&quot;; //指定配置的包路径，避免解析无用的配置 String[] basePackages() default {};} 2.注册配置中心相关类通过实现ImportBeanDefinitionRegistrar方法我们可以获得Bean定义的注册器，此时就可以将我们的功能优雅的注册至spring生命周期内。 值得注意的是，我们设计时采用了spi的方式，在实现的时候采用的是Redis。这就意味着未来如果我们想更换配置管理的方式，完全可以继承现有接口实现一套新的机制。为未来的拓展提供了可能性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class ConfigRegistrar implements ImportBeanDefinitionRegistrar, EnvironmentAware { ..... @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { AnnotationAttributes attributes = AnnotationAttributes .fromMap(importingClassMetadata.getAnnotationAttributes(EnableNadiaConfig.class.getName())); //检查是否需要启动 if (!enableConfig(importingClassMetadata, attributes)) { return; } //初始化需要扫描的包 ConfigRegistrar.setBasePackages(attributes); //工具 BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, SpringUtils.class.getName(), SpringUtils.class); //收集本地环境变量、生成服务信息 //-----&gt;SPI实现，本地变量的手机和Service端显示的服务信息可自定义实现 Map&lt;String, Object&gt; envPropertyValues = new HashMap&lt;&gt;(); envPropertyValues.put(&quot;importingClassMetadata&quot;, importingClassMetadata); InitEnvironment env = SpiServiceUtil.loadFirst(InitEnvironment.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, InitEnvironment.class.getName(), env.getClass(), envPropertyValues); //收集本地配置&amp;回调方法 Map&lt;String, Object&gt; processorPropertyValues = new HashMap&lt;&gt;(); processorPropertyValues.put(&quot;importingClassMetadata&quot;, importingClassMetadata); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, SpringValueProcessor.class.getName(), SpringValueProcessor.class, processorPropertyValues); //启动器注册 BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, ConfigPostConstructProcessor.class.getName(), ConfigPostConstructProcessor.class); //redis装载 ConfigCenter configCenter = SpiServiceUtil.loadFirst(ConfigCenter.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, ConfigCenter.class.getName(), configCenter.getClass()); //按照本地环境变量收集redis中的配置（） //向redis提供当前服务信息 //------&gt;SPI实现，可替换redis为其他中间件 LoadConfig loadConfig = SpiServiceUtil.loadFirst(LoadConfig.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, LoadConfig.class.getName(), loadConfig.getClass()); //配置变更订阅 Listener listener = SpiServiceUtil.loadFirst(Listener.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, Listener.class.getName(), listener.getClass()); //客户端通知服务端 NotifyFactory notifyFactory = SpiServiceUtil.loadFirst(NotifyFactory.class); BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, NotifyFactory.class.getName(), notifyFactory.getClass()); //配置变更启动类 BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, ConfigPostConstructProcessor.class.getName(), ConfigPostConstructProcessor.class); //spring容器关闭时，销毁当前实例信息 BeanRegistrationUtil.registerBeanDefinitionIfNotExists(registry, ApplicationEventListener.class.getName(), ApplicationEventListener.class); } 3.客户端配置的统一收集收集配置时，考虑到把对开发人员的代码侵入性降到最低，我们决定针对Spring自身@Value注解和@ConfigurationProperties注解进行收集。好处是开发人员无需引入其他的学习成本，在不变更现有开发模式下就能进行配置项的收集与管理。 此外，针对配置管理的一些特殊更能，我们设计了扫包路径。开发人员可以根据需要设定扫包路径，从而对关心的配置进行远程管理。同时我们提供了@NadiaConfig注解，一旦标记上该注解后。开发人员可以针对配置的变更进行自定义的回调处理。 12345678910111213141516@Target({ElementType.FIELD,ElementType.CONSTRUCTOR})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface NadiaConfig { Class&lt;? extends Callback&gt; clazz(); CallbackScenes[] callbackScenes() default {CallbackScenes.UPDATE_VALUE, CallbackScenes.SWITCH_GROUP}; boolean exclude() default false; enum CallbackScenes { INIT, SWITCH_GROUP, UPDATE_VALUE, }} 实现BeanPostProcessor接口后，在Bean的后置处理逻辑中我们会收集指定包下的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class SpringValueProcessor extends AbstractMetadata implements BeanPostProcessor, PriorityOrdered { .... private void processField(Object bean, String beanName, Field field) { // register @Value on field Value value = field.getAnnotation(Value.class); if (value == null) { return; } Set&lt;String&gt; keys = PlaceholderHelper.extractPlaceholderKeys(value.value()); if (keys.isEmpty()) { return; } for (String key : keys) { Config config = generateConfig(bean, beanName, key, field); ConfigContextHolder.setConfigHolder(key, config); } } private Config generateConfig(Object bean, String beanName, String key, Field field) { NadiaConfig nadiaConfig = field.getAnnotation(NadiaConfig.class); Class&lt;? extends Callback&gt; callback = null; Set&lt;NadiaConfig.CallbackScenes&gt; callbackScenesSet = null; if (nadiaConfig != null) { if(nadiaConfig.exclude()){ return null; } callback = nadiaConfig.clazz(); callbackScenesSet = getCallbackScenes(nadiaConfig); } return new Config(ConfigTypeEnum.FIELD, beanName, bean.getClass(), key, field, null, FieldUtil.getValue(bean, field), callback, callbackScenesSet, field.getType(), bean); } ....} 4.启动配置本地配置更新的模板流程可以看到，模板模式指定了一套远程配置更新至本地的流程。结合SPI的特性，可以存在多种的实现方式。 123456789101112131415161718192021222324252627282930@Componentpublic class ConfigBootstart { @Autowired private InitEnvironment initEnvironment; @Autowired private LoadConfig loadConfig; @Autowired private Listener listener; @Autowired private NotifyFactory notifyFactory; public void start(){ //bootstart notify start notifyFactory.startPush(); //env initEnvironment.init(); //config loadConfig.load(); loadConfig.updateClientValues(); loadConfig.onlineClientInGroup(); loadConfig.pushClientConfigs(); loadConfig.keepClientAlive(); //watch listener.init(); //bootstart notify end notifyFactory.stopPush(); }} 5.Redis实现配置的更新，客户端的上下线这里我们用Redis实现AbstractLoadConfig定义好的模板方法，包括配置从redis的拉取、更新本地配置、客户端心跳的上报、客户端上线通知、客户端下线通知 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class RedisLoadConfig extends AbstractLoadConfig { @Resource private ConfigCenterRedisService configCenterRedisService; @Resource private RedisPubSub redisPubSub; @Override public void load() { //get redis info this.load(initEnvironment.getClientInfo().getApplication(), initEnvironment.getClientInfo().getGroup()); } @Override public void load(String application, String group) { String configKey = RedisKeyUtil.getGroupConfig(application, group); Map&lt;String, String&gt; configs = configCenterRedisService.hgetAll(configKey); RemoteContextHolder.setRemoteHolder(configKey, configs); } @Override public Object getValue(String key) { return null; } @Override public void onlineClientInGroup() { ClientInfo clientInfo = initEnvironment.getClientInfo(); String applicationGroup = RedisKeyUtil.getInstance(clientInfo.getApplication(), clientInfo.getGroup()); configCenterRedisService.sadd(applicationGroup, clientInfo.getName()); log.info(&quot;========================= onlineClientInGroup key[{}] value[{}] =========================&quot;, applicationGroup, clientInfo.getName()); } @Override public void offlineClientInGroup() { ClientInfo clientInfo = initEnvironment.getClientInfo(); String applicationGroup = RedisKeyUtil.getInstance(clientInfo.getApplication(), clientInfo.getGroup()); configCenterRedisService.del(applicationGroup, clientInfo.getName()); log.info(&quot;========================= offlineClientInGroup key[{}] value[{}] =========================&quot;, applicationGroup, clientInfo.getName()); } @Override public void offlineClientConfigs() { ClientInfo clientInfo = initEnvironment.getClientInfo(); String instanceConfig = RedisKeyUtil.getInstanceConfig(clientInfo.getApplication(), clientInfo.getGroup(), clientInfo.getName()); configCenterRedisService.del(instanceConfig); log.info(&quot;========================= offlineClientConfigs key[{}] =========================&quot;, instanceConfig); } @Override public void keepClientAlive() { ClientInfo clientInfo = initEnvironment.getClientInfo(); //push client info to redis schedule Executors.newScheduledThreadPool(1).scheduleAtFixedRate(new Runnable() { @Override public void run() { log.info(&quot;========================= Client Keep Alive with Redis Start =========================&quot;); clientInfo.setTimestamp(new Date().getTime()); String hashCode = String.valueOf(clientInfo.hashCode()); log.info(&quot;========================= Client Keep Alive hashCode:[{}] clientInfo:[{}] =========================&quot;, hashCode, clientInfo); configCenterRedisService.hset(RedisKeyUtil.getClints(), hashCode, JSONObject.toJSONString(clientInfo)); log.info(&quot;========================= Client Keep Alive with Redis End =========================&quot;); } }, 0, 1, TimeUnit.MINUTES); } @Override public void pushClientConfig(String key, String value) { String configKey = RedisKeyUtil.getInstanceConfig(initEnvironment.getClientInfo().getApplication(), initEnvironment.getClientInfo().getGroup(), initEnvironment.getClientInfo().getName()); configCenterRedisService.hset(configKey, key, value); } @Override public void pushClientConfigs() { ClientInfo clientInfo = initEnvironment.getClientInfo(); configCenterRedisService.del(RedisKeyUtil.getInstanceConfig(clientInfo.getApplication(), clientInfo.getGroup(), clientInfo.getName())); Map&lt;String, String&gt; clientConfigs = ConfigContextHolder.getClientConfigs(); clientConfigs.forEach((k, v) -&gt; { configCenterRedisService.hset(RedisKeyUtil.getInstanceConfig(clientInfo.getApplication(), clientInfo.getGroup(), clientInfo.getName()), k, v); }); } @Override protected void notificServer(String message,EventType type , LogLevelEnum level) { redisPubSub.notifyServer(initEnvironment.getClientInfo(), type, level,message); } @Override public void offlineClientInfo() { ClientInfo clientInfo = initEnvironment.getClientInfo(); configCenterRedisService.del(RedisKeyUtil.getClints(),String.valueOf(clientInfo.hashCode())); log.info(&quot;========================= delete client info key[{}] value[{}]=========================&quot;, RedisKeyUtil.getClints(),clientInfo.hashCode()); } @Override public void pushClinetInfo() { ClientInfo clientInfo = initEnvironment.getClientInfo(); configCenterRedisService.hset(RedisKeyUtil.getClints(), String.valueOf(clientInfo.hashCode()), JSONObject.toJSONString(clientInfo)); log.info(&quot;========================= push client info key[{}] value[{}]=========================&quot;, RedisKeyUtil.getClints(),clientInfo.hashCode()); }} 6.Redis实现远程配置的实时同步配置信息的实时同步主要采用了Redis的监听功能，客户端启动后监听特殊通道的信息，并剥离出自己感兴趣的信息进行处理。 123456789101112131415161718192021222324252627282930313233343536373839class MyMessageListener implements MessageListener { private LoadConfig loadConfig; MyMessageListener(LoadConfig loadConfig) { this.loadConfig = loadConfig; } @Override public void onMessage(Message message, byte[] pattern) { notifyFactory.startPush(); MessageBody messageBody = MessageConvert.unpackageMessage(message.toString()); if (messageBody instanceof UpdateValueMessageBody) { log.info(&quot;receive UpdateValueMessageBody start&quot;); redisPubSub.notifyServer(initEnvironment.getClientInfo(), EventType.CLIENT_MESSAGE, LogLevelEnum.LOG,&quot;receive UpdateValueMessageBody start&quot;); UpdateValueMessageBody updateValueMessageBody = (UpdateValueMessageBody) messageBody; String group = initEnvironment.getClientInfo().getGroup(); if (group.equals(updateValueMessageBody.getGroup())) { //updateClientValue local value boolean hasFaile = loadConfig.updateClientValue(updateValueMessageBody.getKey(), updateValueMessageBody.getValue(), NadiaConfig.CallbackScenes.UPDATE_VALUE); if(!hasFaile){ Object oldValue = ConfigContextHolder.getOldValue(updateValueMessageBody.getKey()); // update server value loadConfig.pushClientConfig(updateValueMessageBody.getKey(), ClientValueUtil.serializer(updateValueMessageBody.getValue(), oldValue)); } } } else if (messageBody instanceof SwitchInstanceMessageBody) { log.info(&quot;receive SwitchInstanceMessageBody start&quot;); redisPubSub.notifyServer(initEnvironment.getClientInfo(), EventType.CLIENT_MESSAGE, LogLevelEnum.LOG,&quot;receive SwitchInstanceMessageBody start&quot;); SwitchInstanceMessageBody switchInstanceMessageBody = (SwitchInstanceMessageBody) messageBody; //update local value loadConfig.switchGroup(switchInstanceMessageBody.getApplication(),switchInstanceMessageBody.getGroupFrom(),switchInstanceMessageBody.getGroupTo(),switchInstanceMessageBody.getInstance()); } else if (messageBody instanceof HeartbeatMessageBody) { log.info(&quot;receive HeartbeatMessageBody&quot;); } notifyFactory.stopPush(); } }","link":"/2020/04/18/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E9%87%8D%E6%96%B0%E5%86%99%E4%B8%80%E4%B8%AA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-%E4%BB%A3%E7%A0%81%E7%AF%87/"},{"title":"深度剖析JVM 动态Attach原理","text":"相信很多小伙伴都使用过javaagent探针技术，javaagent可以在不侵入原代码不的前提下，通过指定方法并利用动态字节码技术增强我们的代码。很多成熟的框架也运用到了该技术，如skywalking等。这么好用的功能，JDK的开发人员没道理不玩出些新花头，因此在JDK1.6中，更加强大的JVM 动态Attach技术展现在我们的面前。大名鼎鼎的Btrace、Arthas等都运用了动态Attach技术。在JVM运行期进拦截并增强我们的代码，使得以往生产难以定位的问题变得更加容易排查。 JVM的动态Attach固然好，相信大家或多或少已经知道如何去使用该技术了，所以这次我们研究的重点是JVM是如何实现动态Attach，至于JVM如何加载动态Jar包、分发方法并传递jvm上下文就不在我们的研究范围之内。 为了更好的研究JVM的实现，我们将由浅入深，分为几个阶段进行研究： 动态Attach是什么？ 有几种方案可以实现动态Attach 举一个栗子 看看JVM是怎么做的 一、动态Attach是什么虽然我们这次研究的是具体的实现，但在这之前，我们需要像分析需求一样分析下动态Attach到底是什么。 我们都知道javaagent参数是伴随着java命令，在JVM启动的过程中加载javaagent参数指定的Jar包路径，并执行约定类的premain方法。在premain方法中可以获取Instrumentation类型参数，从而对我们的类进行动态增强增强。 我们可以这样使用javaagent： 先实现一个我们需要挂在的类，其中需要实现premain()方法，并将它打包为可执行Jar包 123456789101112131415public class Javaagent { public static void premain(String agentArgs, Instrumentation inst) { System.out.println(&quot;agentArgs : &quot; + agentArgs); inst.addTransformer(new TestTransformer(), true); } static class TestTransformer implements ClassFileTransformer { @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(&quot;premain load Class:&quot; + className); return classfileBuffer; } }} 配置MANIFEST.MF配置文件 1234Premain-Class: JavaagentAgent-Class: JavaagentCan-Redefine-Classes: trueCan-Retransform-Classes: true 启动我们的服务 1java -javaagent:Javaagent.jar 自己的服务.jar 以上就是一个简单的javaagent运用场景。javaagent可以在不侵入业务代码的前提下修改我们已加载的类，但唯一的问题是需要伴随着业务服务一同启动。也就是说我们无法侵入已经运行在JVM中的代码，因此JDK开发的大神们为我们带来了动态Attach API。其功能与javaagent是一样的，但最大的好处就是我们能够在一个已经运行的JVM上动态的挂载一个我们自己开发的Jar包，从而实现任何时间点我们都能手动的增强业务代码。比如通过attach Arthas，我们能增强指定方法的入口&amp;出口，从而获取出入参的相关信息。这在缺少日志输出的场景下是非常有效的问题定位手段。此外我们也能为方法的调用链做埋点，帮助我们分析业务流程中的慢方法等等。 总结下，动态Attach就是JVM运行期中提供的指定类型的类加载机制。通过增强类的加载，实现各式各样有趣的功能。 二、有几种方案可以实现动态Attach现在我们已经知道什么是动态Attach了，倘若我们是JDK的工程师，当产品交给我们需要实现动态Attach这个需求时，我们会怎么实现呢？ 1.直接类加载法JDK已经提供了一套完善的类加载机制，如果提供获取Instrumentation对象的JNI，开发人员就可以自行通过动态类加载后进行字节码动态增强。这个方案看似很美好，现有Java生态圈已经拥有丰富的Class动态加载方案，利用这些现有方案，开发人员能够很快的搭建出自己的字节码动态加载机制，而无需JVM提供大量的native支持。但是这个方案存在重大的安全问题，一旦服务的动态加载机制被黑客破解，那么他完全能够加载一个自己编写好的侵入类，通过入侵类任意修改业务代码最终导致无法挽回的损失。所以作为一个JDK开发工程师，一定要在初期就屏蔽这种安全问题。同时Java最为一种安全语言，不安全的操作需要尽量避免引入Java生态中。 2.Socket通信法既然提供JNI不安全，那么我们是否可以考虑让JVM自己处理。假设我们能和JVM建立起Socket通讯。并将我们希望加载的类告知JVM，JVM在加载完成后按照约定执行指定的入口方法，这样也能实现我们对动态Attach的实现。 Socket通信可以分为远程通信和本地通信。我们需要考虑，如果采用远程通信，的确能给我们带来更强大的Attach灵活性，但需要JVM暴露端口，同样具有一定的安全问题。本地通讯我们可以采用UNIX Domain Socket，通过文件形式通讯。不但具有较高的通信速度，同时具有一定的安全性。 如果采用Socket Local通信，那我们又如何与JVM建立起通信呢？ 3.信号监听法其实这个方法是Socket通信法的补充。在与JVM建立起本地通信前，JVM需要知道用户想要开始动态Attach。而信号监听就能补充这方面的功能。客户端以约定的形式向JVM进程发起指定信号，同时JVM在监听到Attach信号后与客户端建立Socket链接。客户端以Socket方式将需要加载的类告知JVM并进行加载并最终运行我们后面熟悉的javaagent流程。 我虽然不是JDK的工程师，上面的3个方案也是结合了JDK1.8的具体实现后大胆的揣测了当时开发工程师的想法。可能当时摆在他面前的方案更是成千上万，但是最终确定下这个技术方案的心路历程我觉得是我们每个开发都需要感同身受的。 三、举一个栗子前面我们分析了实现方案，我们先丢一份代码来验证上面的方案（代码为JDK1.8源码相关功能的简化版） 开始实验需求：实现动态Attach API，接收java -jar xxx.jar pid发起的挂载请求，并将loadAgent指定的Jar包完整路径显示在控制台。 实验环境：MacOS 10.15.6 项目地址： https://github.com/xzenge/JVM_ATTACH/tree/dev 我们先启动项目。该项目模拟了JVM运行环境，但只实现了Attach API的部分功能。项目启动成功后，我们可以看到当前的JVM进程ID为：32910 按照JDK规范编写JAVA测Attach方法。为了简便，方法中我们手动指定了attach的线程号，并提供了JVM需要加载的Jar包路径。123456789public class Attach { public static void main(String[] args) throws IOException, AttachNotSupportedException, AgentLoadException, AgentInitializationException { VirtualMachine attach = VirtualMachine.attach(&quot;32910&quot;); attach.loadAgentPath(&quot;/Users/xiangshi/.gradle/caches/modules-2/files-2.1/cglib/cglib/3.1/1f1cb6c7a7479e0c7fd7987109e503914bebe84a/cglib-3.1.jar&quot;); }} 运行Java attach方法，我们可以观察到模拟的JVM已经读取到了我们希望classloader的Jar包 实验分析实验过程很简单，我们伪造了个JVM运行时环境。并通过JAVA原生的Attach API成功的实现了与JVM之间通讯的功能。下面我们开始逐步分析具体的实现过程： 监听signal初始化OS信号监听的相关数据 123456789101112/** * JVM启动时监听signal */void os::signal_init() { //初始化signal监听pending_signals os::signal_init_pd(); //创建线程监听pending_signals状态并进行相应处理 pthread_t tids; int ret = pthread_create(&amp;tids, NULL, reinterpret_cast&lt;void *(*)(void *)&gt;(signal_thread_entry), NULL); //注册signal处理器 os::signal(SIGBREAK,os::user_handler());} sigaction方法提供os信号的监听并注册信号处理器，我们监听-3 SIGQUIT信号。 1234567891011121314151617181920/** * 注册监听信号&amp;处理器 * @param signal_number 信号编号 * @param handler 信号处理器 * @return */void *os::signal(int signal_number, void *handler) { struct sigaction sigAct, oldSigAct; sigfillset(&amp;(sigAct.sa_mask)); sigAct.sa_flags = SA_RESTART|SA_SIGINFO; sigAct.sa_handler = CAST_TO_FN_PTR(sa_handler_t, handler); if (sigaction(signal_number, &amp;sigAct, &amp;oldSigAct)) { // -1 means registration failed return (void *)-1; } return CAST_FROM_FN_PTR(void*, oldSigAct.sa_handler);} 信号处理器中简单的模拟的收到信号的处理过程，数组对应的信号位置为1时，说明收到了对应的信号。 12345678910111213/** * 通过pending_signals保留监听到的信息，交由专门的线程处理该信息 * @param signal_number */void os::signal_notify(int signal_number) { cout &lt;&lt; &quot;enter signal_notify sig:&quot; &lt;&lt; signal_number &lt;&lt; endl; //将监听到的信号为竖为1 //改操作应该为原子操作，确保不会被其他线程修改 //JVM中混编平台相关汇编指令实现原子操作，演示代码中不研究相关实现 pending_signals[signal_number] = 1; semaphore_signal(sig_sem);} 单独起一个线程，该线程轮训信号接受数组的状态，将置为1的信号码传给下游处理。当信号位-3 SIGQUIT信号时，开始初始化attach的监听方法。 1234567891011121314151617181920/** * 单独线程对pending_signals状态并进行相应处理 */static void signal_thread_entry() { cout &lt;&lt; &quot;enter signal_thread_entry&quot; &lt;&lt; endl; while (true){ int sig; { sig = os::signal_wait(); } switch (sig) { case SIGBREAK: { if (AttachListener::init()) { continue; } } } }} 初始化attach监听方法时，会创建一个Domain Socket的文件监听，并accept在改文件上。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 初始化domain socket监听 * JVM通过监听指定线程文件文件 * 获取client想JVM发送的指令并进行相关操作 * @return */int AttachListener::pd_init() { char path[UNIX_PATH_MAX]; // socket file char initial_path[UNIX_PATH_MAX]; // socket file during setup int listener; // listener socket (file descriptor) // register function to cleanup ::atexit(listener_cleanup); int n = snprintf(path, UNIX_PATH_MAX, &quot;%s/.java_pid%d&quot;, TEMP_PATH, getpid()); if (n &lt; (int) UNIX_PATH_MAX) { n = snprintf(initial_path, UNIX_PATH_MAX, &quot;%s.tmp&quot;, path); } if (n &gt;= (int) UNIX_PATH_MAX) { return -1; } cout &lt;&lt; &quot;path:&quot; &lt;&lt; path &lt;&lt; endl; // create the listener socket listener = ::socket(PF_UNIX, SOCK_STREAM, 0); if (listener == -1) { return -1; } // bind socket struct sockaddr_un addr; addr.sun_family = AF_UNIX; strcpy(addr.sun_path, initial_path); ::unlink(initial_path); int res = ::bind(listener, (struct sockaddr *) &amp;addr, sizeof(addr)); if (res == -1) { ::close(listener); return -1; } // put in listen mode, set permissions, and rename into place res = ::listen(listener, 5); if (res == 0) { RESTARTABLE(::chmod(initial_path, S_IREAD | S_IWRITE), res); if (res == 0) { if (res == 0) { res = ::rename(initial_path, path); } } } if (res == -1) { ::close(listener); ::unlink(initial_path); return -1; } set_path(path); set_listener(listener); return 0;} 一旦收到java发送过来的socket请求，则解析该请求并包装为AttachOperation对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * accept domain socket，读取到内容后生成对应的AttachOperation * @return */AttachOperation *AttachListener::dequeue() { for (;;) { int s; // wait for client to connect struct sockaddr addr; socklen_t len = sizeof(addr); RESTARTABLE(::accept(listener(), &amp;addr, &amp;len), s); if (s == -1) { return NULL; // log a warning? } // get the credentials of the peer and check the effective uid/guid // - check with jeff on this. uid_t puid; gid_t pgid; if (::getpeereid(s, &amp;puid, &amp;pgid) != 0) { ::close(s); continue; } uid_t euid = geteuid(); gid_t egid = getegid(); //检查DS文件是否为同一个用户创建 if (puid != euid || pgid != egid) { ::close(s); continue; } // 读取文件内容，生成AttachOperation对象 AttachOperation *op = read_request(s); if (op == NULL) { ::close(s); continue; } else { return op; } }} 最后用包装后的AttachOperation，通过函数指针调用已绑定的处理函数。 1234567891011121314151617181920212223242526272829static void attach_listener_thread_entry() { int pdint = AttachListener::pd_init(); if (pdint != 0) { return; } AttachListener::set_initialized(); for (;;) { AttachOperation* op = AttachListener::dequeue(); if (op == NULL) { return; // dequeue failed or shutdown } // find the function to dispatch too AttachOperationFunctionInfo* info = NULL; for (int i=0; funcs[i].name != NULL; i++) { const char* name = funcs[i].name; if (strcmp(op-&gt;name(), name) == 0) { info = &amp;(funcs[i]); break; } } if (info != NULL) { // dispatch to the function that implements this operation (info-&gt;func)(op); } }} 总结 ，通过信号监听–&gt;socket通信–&gt;调用指定方法的流程，实现了我们实验的预期。 四、看看JVM是怎么做的最后我们回到JVM内部，看看JVM是如何实现的。 由于实验代码大量的采用了JVM的实现，我们这里主要观察JVM的流程。 JVM启动时会初始化信号的监听 代码清单：src/share/vm/runtime/thread.cpp 123456789101112131415jint Threads::create_vm(JavaVMInitArgs* args, bool* canTryAgain) { ... // Signal Dispatcher needs to be started before VMInit event is posted os::signal_init(); // Start Attach Listener if +StartAttachListener or it can&apos;t be started lazily if (!DisableAttachMechanism) { AttachListener::vm_start(); if (StartAttachListener || AttachListener::init_at_startup()) { AttachListener::init(); } } ...} os::signal_init();功能我们前面已经分析过，JVM会注册kill -3信号的监听和对应的信号处理器，同时会启动一个单独的线程对监听到的信号做后续业务处理。 DisableAttachMechanism &amp; StartAttachListener 默认为false，在JVM默认启动的情况下不会初始化Attach的监听。 代码清单：src/share/vm/runtime/globals.hpp 1234product(bool, DisableAttachMechanism, false, \\ &quot;Disable mechanism that allows tools to attach to this VM&quot;) product(bool, StartAttachListener, false, \\ &quot;Always start Attach Listener at VM startup&quot;) JVM监听到信号后，当信号位kill -3时如果还未初始化attach监听，将会进行相应初始化过程。 代码清单：src/share/vm/runtime/thread.cpp-&gt;create_vm() —- src/share/vm/runtime/os.cpp-&gt;signal_init() —- src/share/vm/runtime/os.cpp-&gt;signal_thread_entry() 123456789101112131415161718192021222324252627282930313233343536373839404142434445static void signal_thread_entry(JavaThread* thread, TRAPS) { os::set_priority(thread, NearMaxPriority); while (true) { int sig; { // FIXME : Currently we have not decieded what should be the status // for this java thread blocked here. Once we decide about // that we should fix this. sig = os::signal_wait(); } if (sig == os::sigexitnum_pd()) { // Terminate the signal thread return; } switch (sig) { case SIGBREAK: { // Check if the signal is a trigger to start the Attach Listener - in that // case don&apos;t print stack traces. if (!DisableAttachMechanism &amp;&amp; AttachListener::is_init_trigger()) { continue; } // Print stack traces // Any SIGBREAK operations added here should make sure to flush // the output stream (e.g. tty-&gt;flush()) after output. See 4803766. // Each module also prints an extra carriage return after its output. VM_PrintThreads op; VMThread::execute(&amp;op); VM_PrintJNI jni_op; VMThread::execute(&amp;jni_op); VM_FindDeadlocks op1(tty); VMThread::execute(&amp;op1); Universe::print_heap_at_SIGBREAK(); if (PrintClassHistogram) { VM_GC_HeapInspection op1(gclog_or_tty, true /* force full GC before heap inspection */); VMThread::execute(&amp;op1); } if (JvmtiExport::should_post_data_dump()) { JvmtiExport::post_data_dump(); } break; } ... }} 初始化Attach监听时会检查Java客户端生成的attach文件。 代码清单：src/share/vm/runtime/thread.cpp-&gt;create_vm() —- src/share/vm/runtime/os.cpp-&gt;signal_init() —- src/share/vm/runtime/os.cpp-&gt;signal_thread_entry() —- src/os/bsd/vm/attachListener_bsd.cpp-&gt;is_init_trigger() 123456789101112131415161718192021bool AttachListener::is_init_trigger() { if (init_at_startup() || is_initialized()) { return false; // initialized at startup or already initialized } char path[PATH_MAX + 1]; int ret; struct stat st; snprintf(path, PATH_MAX + 1, &quot;%s/.attach_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); RESTARTABLE(::stat(path, &amp;st), ret); if (ret == 0) { // simple check to avoid starting the attach mechanism when // a bogus user creates the file if (st.st_uid == geteuid()) { init(); return true; } } return false;} 确认Java客户端开始attach并且权限校验通过后开始socket通讯，首先初始化socket并绑定监听。 代码清单： src/os/bsd/vm/attachListener_bsd.cpp-&gt;is_init_trigger() —- src/share/vm/services/attachListener.cpp-&gt;init() 123456789101112131415161718192021bool AttachListener::is_init_trigger() { if (init_at_startup() || is_initialized()) { return false; // initialized at startup or already initialized } char path[PATH_MAX + 1]; int ret; struct stat st; snprintf(path, PATH_MAX + 1, &quot;%s/.attach_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); RESTARTABLE(::stat(path, &amp;st), ret); if (ret == 0) { // simple check to avoid starting the attach mechanism when // a bogus user creates the file if (st.st_uid == geteuid()) { init(); return true; } } return false;} 最终JVM创建了一个单独的线程执行Attach监听方法，方法accept从Java客户端发送的指令，并解析为对应的函数。 代码清单： src/share/vm/services/attachListener.cpp-&gt;init() —- src/share/vm/services/attachListener.cpp-&gt;attach_listener_thread_entry() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253static void attach_listener_thread_entry(JavaThread* thread, TRAPS) { os::set_priority(thread, NearMaxPriority); thread-&gt;record_stack_base_and_size(); if (AttachListener::pd_init() != 0) { return; } AttachListener::set_initialized(); for (;;) { AttachOperation* op = AttachListener::dequeue(); if (op == NULL) { return; // dequeue failed or shutdown } ResourceMark rm; bufferedStream st; jint res = JNI_OK; // handle special detachall operation if (strcmp(op-&gt;name(), AttachOperation::detachall_operation_name()) == 0) { AttachListener::detachall(); } else { // find the function to dispatch too AttachOperationFunctionInfo* info = NULL; for (int i=0; funcs[i].name != NULL; i++) { const char* name = funcs[i].name; assert(strlen(name) &lt;= AttachOperation::name_length_max, &quot;operation &lt;= name_length_max&quot;); if (strcmp(op-&gt;name(), name) == 0) { info = &amp;(funcs[i]); break; } } // check for platform dependent attach operation if (info == NULL) { info = AttachListener::pd_find_operation(op-&gt;name()); } if (info != NULL) { // dispatch to the function that implements this operation res = (info-&gt;func)(op, &amp;st); } else { st.print(&quot;Operation %s not recognized!&quot;, op-&gt;name()); res = JNI_ERR; } } // operation complete - send result and output to client op-&gt;complete(res, &amp;st); }} 代码清单： src/share/vm/services/attachListener.cpp-&gt;attach_listener_thread_entry() —- src/os/bsd/vm/attachListener_bsd.cpp-&gt;dequeue() —- src/os/bsd/vm/attachListener_bsd.cpp-&gt;BsdAttachListener::dequeue() 1234567891011121314151617181920212223242526272829303132333435363738BsdAttachOperation* BsdAttachListener::dequeue() { for (;;) { int s; // wait for client to connect struct sockaddr addr; socklen_t len = sizeof(addr); RESTARTABLE(::accept(listener(), &amp;addr, &amp;len), s); if (s == -1) { return NULL; // log a warning? } // get the credentials of the peer and check the effective uid/guid // - check with jeff on this. uid_t puid; gid_t pgid; if (::getpeereid(s, &amp;puid, &amp;pgid) != 0) { ::close(s); continue; } uid_t euid = geteuid(); gid_t egid = getegid(); if (puid != euid || pgid != egid) { ::close(s); continue; } // peer credential look okay so we read the request BsdAttachOperation* op = read_request(s); if (op == NULL) { ::close(s); continue; } else { return op; } }} 指令与方法的映射是事先准备好的 代码清单：src/share/vm/services/attachListener.cpp 12345678910111213static AttachOperationFunctionInfo funcs[] = { { &quot;agentProperties&quot;, get_agent_properties }, { &quot;datadump&quot;, data_dump }, { &quot;dumpheap&quot;, dump_heap }, { &quot;load&quot;, JvmtiExport::load_agent_library }, { &quot;properties&quot;, get_system_properties }, { &quot;threaddump&quot;, thread_dump }, { &quot;inspectheap&quot;, heap_inspection }, { &quot;setflag&quot;, set_flag }, { &quot;printflag&quot;, print_flag }, { &quot;jcmd&quot;, jcmd }, { NULL, NULL }}; 总结,相信通过上面的分析我们已经清楚的了解JVM是如何接收到Java客户端发起的请求，从而实现动态Attach的功能。具体流程如图：","link":"/2020/09/21/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90JVM-%E5%8A%A8%E6%80%81Attach%E5%8E%9F%E7%90%86/"},{"title":"JAVA 原子操作及对比","text":"原子操作是并发同步的一种运用场景，Java提供了多种原子操作的工具类。这里我们总结下各个工具的使用方法及其优缺点。 1.AtomicXXXX类AtomicXXXX全家桶提供了各种基础类型的包装类型的原子对象。通过声明一个Atomic类型的对象对变量进行线程安全的操作。 源码分析Atomic对象内部持有Unsafe对象，并通过Unsafe对象获取操作数所在的Atomic对象在内存中的偏移量。（可以理解为在C中持有改变量的指针） 123private static final Unsafe U = Unsafe.getUnsafe();private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, &quot;value&quot;); 对变量的操作采用Unsafe提供的CAS接口，通过循环比较最终保证变量的更新成功 1234567891011public final int getAndSet(int newValue) { return U.getAndSetInt(this, VALUE, newValue);}public final int getAndSetInt(Object o, long offset, int newValue) { int v; do { v = getIntVolatile(o, offset); } while (!weakCompareAndSetInt(o, offset, v, newValue)); return v;} linux_X86下可以看到JVM内部提供了Atomic类下的cmpxchg的方法 123456UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END cmpxchg的实现也比较巧妙，首先会判断运行环境为多进程还是单进程。单进程下不需要对内存加锁，对变量直接进行操作。而多进程下使用了cmpxchgl指令保证了变量的原子操作。这里我们可以看到JVM内部的实现采用了内嵌汇编的方式，同时最大的优化的单进程下的执行效率。不采用调用内核提供的同步接口，减少了内核态和用户态切换所导致的成本。 12345678910#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot;inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) { int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value;} 优点 使用简单，语义清晰； 对各种类型支持较好。 缺点 可移植性差，对非Atomic变量的改造成本较高; 内存消耗较大，除了变量本身，实例变量需要占用额外的内存; 高并发场景下由于lock指令需要锁缓存，导致性能下降。 2.XXXXAdderLongAdder、DoubleAdder只提供了Long和Double类型的+1、-1操作。 源码分析LongAdder的思想是，多核、多线程场景下。每个线程独立计算，最终合计所有线程的累计值。在单线程场景下，通过cas保证base值的安全累加。一旦cas失败，或者之前产多多核的场景时，通过longAccumulate方法分别合计不同线程下的值。 1234567891011121314public void increment() { add(1L);}public void add(long x) { Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) { boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); }} longAccumulate作为LongAddre中的核心方法，主要是为每个线程维护了Cell类型的数组。具体实现我们下次另起一篇重讲。 优点 使用简单，语义清晰； 高并发场景下，性能比Atomic类强。 缺点 对类型的支持有限，现只支持Long和Double类型； 多并发场景下可能会导致统计出现误差。 3.XXXXFieldUpdaterXXXXFieldUpdater工具类通过反射获取对象内的变量，从而对对象进行原子操作。 源码分析使用FieldUpdater时，方法通过对类的反射获取Class、Field的相应信息。最后还是通过Unsafe方法获取变量在结构体中的偏移量，从而进行操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647AtomicIntegerFieldUpdaterImpl(final Class&lt;T&gt; tclass, final String fieldName, final Class&lt;?&gt; caller) { final Field field; final int modifiers; try { field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() { public Field run() throws NoSuchFieldException { return tclass.getDeclaredField(fieldName); } }); modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) { sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); } } catch (PrivilegedActionException pae) { throw new RuntimeException(pae.getException()); } catch (Exception ex) { throw new RuntimeException(ex); } if (field.getType() != int.class) throw new IllegalArgumentException(&quot;Must be integer type&quot;); if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException(&quot;Must be volatile type&quot;); // Access to protected field members is restricted to receivers only // of the accessing class, or one of its subclasses, and the // accessing class must in turn be a subclass (or package sibling) // of the protected member&apos;s defining class. // If the updater refers to a protected field of a declaring class // outside the current package, the receiver argument will be // narrowed to the type of the accessing class. this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; tclass.isAssignableFrom(caller) &amp;&amp; !isSamePackage(tclass, caller)) ? caller : tclass; this.tclass = tclass; this.offset = U.objectFieldOffset(field);} 而提供的原子操作和Atomic类原理一样 12345678public int incrementAndGet(T obj) { int prev, next; do { prev = get(obj); next = prev + 1; } while (!compareAndSet(obj, prev, next)); return next;} 优点 不需要对类，或者成员变量进行修改就能执行原子操作，对代码移植友好。 缺点 和Atomic一样，会存在高并发下的性能问题。主要还是由于对缓存上锁导致的。 变量只支持int类型，且必须为volatile修饰的。 4.VarHandle变量句柄是JDK1.9提供的新特性。在替代Atomic和Unsafe方法的同时，提供更加细粒度的内存屏障API。 源码分析可以看到，通过方法句柄获取到变量句柄的对象，并对对象进行原子操作。 1234567891011121314151617public static void main(String[] args) { VarHandle varHandle; try { varHandle = MethodHandles.lookup(). in(Foo.class). findVarHandle(Foo.class, &quot;i&quot;, int.class); Foo f = new Foo(); System.out.println(&quot;before add: &quot;+f.i); for(int i = 0;i&lt;10;i++){ int o = (int) varHandle.getAndAdd(f, 1); } System.out.println(&quot;after add: &quot;+f.i); } catch (Exception e) { throw new Error(e); }} 方法句柄和变量句柄的实现较为复杂，我们下次另开一篇详细介绍JVM如何实现MethodHandle和VarHandle，并且详细分析原子操作和内存屏障实现的细节。 优点 不需要对类，或者成员变量进行修改就能执行原子操作，对代码移植友好； 对各种类型支持完善； 语义粒度更加细，提供更加细致、安全的内存操作方式。 缺点 新东西吧。。。学习成本比较高。 总结以上，我们大致总结了Java在原子操作上的相关处理。原子操作是多线程同步的一种实际运用，显示、或非显示的对临界区进行并发上的保护。关于并发，JVM做了相当多的优化，我们有时间慢慢抽丝剥茧，好好学习下JVM在并发下的各种处理。","link":"/2020/12/30/JAVA-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E5%8F%8A%E5%AF%B9%E6%AF%94/"},{"title":"配置中心(nadia-config)  船新版本","text":"大扎好，我系xzenge! nadia-config-plus，介四里没有挽过的船新版本，挤需体验三番钟，里造会干我一样，爱象节款工具！ https://github.com/nadia-repository/nadia-config 谢谢看到这篇文章或是使用过nadia-config的大家。2021的农历新年也快到了，赶在新年的前一天，为大家带来nadia-config的全新版本，同时也给大家拜个早年。2020着实不易，希望每位仍在摸爬滚打的技术人们(包括我自己)，新的一年仍然能坚守自己的技术初心，也愿大家的技术梦想都能尽早实现，挥去2020的阴霾，未来的每一天都是充满希望的一天。 nadia-config的诞生最早是因为看到公司的配置中心用起来非常糟心，服务接入不灵活、很难契合公司的业务。思来想去自己私下撸了一个最初的版本尝试在公司推广。一来二去没想到各部门的小伙伴反馈都还不错，就这样成为了公司内部正式推广的项目，也随之完善了本次更新的各个功能和bug。 nadia-config未来会变成什么样，一直以来我都会不停思考这个问题。除了公司内部功能的迭代，我自己也会为nadia-config维护一个单独的个人版本进行开源。当初nadia-config的很多灵感来自于Apollo和XXL，研究过他们的代码后nadia-config也多少带有他们的影子，所以最开始设计nadia-config的时候就没有避讳一定要和谁不一样或是哪方面要和谁做的一样。 因此接下来的工作将会围绕在nadia-config的高可用和集群上。目前我的实现还是停留在对redis的依赖，虽然提供了完善的SPI对第三方的支持，但毕竟都是各家各有所长，择其一就要放弃另外一个。说的通俗一点，接下来会实现自己的分布式管理模块。可想而知工作量巨大，对整个nadia-config的架构也是一次巨大的调整。但我觉得这一步是必然的，生态的闭环需要技术和组件的支持，类比编程语言的话，一个成熟的语言伴随着自举，那项目的成熟自然是伴随的内部组件的完善，也就是对外部组件的剥离。这条路上我们有很多优秀的前辈可以给我们做参考。zookeeper、RocketMq的Namesrv等等都是我们未来学习并融合的方向。 说道底nadia-config会变成什么？我敢肯定的是它不会变成像Nacos一样大而全的如同瑞士军刀般的存在，但是她一定是一把趁手的砍刀，拿得起放得下！ 更新日期 2021-02-10 功能升级 客户端支持多Application，提升配管理的灵活性，解决现有冗余配置的问题； 升级客户端在服务端Metadata中注册的信息，提升客户端支持多Application的可读性； 优化服务端剔除超时客户端的逻辑； 放开服务端配置项大小的限制； bug修改 修改redis线程池数量，解决获取连接失败问题； 修复服务端删除缓存时，远程缓存删除失败问题； 修复配置变更后，客户端回调方法报错问题； 修复客户端维持信条时，由于异常导致的心跳失败问题； 修复@NadiaConfig注解中，排除功能导致的异常问题； 修复服务端配置项不能为空的问题； 修复客户端上报日志后，服务端无法正常消费的问题；","link":"/2021/02/10/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83-nadia-config-%E8%88%B9%E6%96%B0%E7%89%88%E6%9C%AC/"}],"tags":[{"name":"CSAPP","slug":"CSAPP","link":"/tags/CSAPP/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"Harmonica","slug":"Harmonica","link":"/tags/Harmonica/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"IO","slug":"IO","link":"/tags/IO/"},{"name":"Springboot","slug":"Springboot","link":"/tags/Springboot/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"Cache","slug":"Cache","link":"/tags/Cache/"},{"name":"GCC","slug":"GCC","link":"/tags/GCC/"},{"name":"代码优化","slug":"代码优化","link":"/tags/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/"},{"name":"Flink","slug":"Flink","link":"/tags/Flink/"},{"name":"监控","slug":"监控","link":"/tags/%E7%9B%91%E6%8E%A7/"},{"name":"配置中心","slug":"配置中心","link":"/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"APP","slug":"APP","link":"/tags/APP/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Food","slug":"Food","link":"/tags/Food/"},{"name":"fastjson","slug":"fastjson","link":"/tags/fastjson/"},{"name":"ASM","slug":"ASM","link":"/tags/ASM/"}],"categories":[{"name":"Technology","slug":"Technology","link":"/categories/Technology/"},{"name":"Music","slug":"Music","link":"/categories/Music/"},{"name":"Translation","slug":"Translation","link":"/categories/Translation/"},{"name":"Life","slug":"Life","link":"/categories/Life/"}]}